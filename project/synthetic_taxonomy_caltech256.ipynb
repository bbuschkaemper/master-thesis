{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a8a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchvision.datasets import Caltech256\n",
    "\n",
    "\n",
    "caltech256_labels = Caltech256(root=\"datasets/caltech256\", download=False).categories\n",
    "caltech256_targets = pd.read_csv(\"data/caltech256.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082703e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'foreign_prediction_distributions' from 'library.utils' (/home/sentinel/Development/master-thesis/project/library/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtaxonomy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Taxonomy\n\u001b[32m      4\u001b[39m synthetic_taxonomy, domains = Taxonomy.create_synthetic_taxonomy(\n\u001b[32m      5\u001b[39m     num_atomic_concepts=\u001b[32m257\u001b[39m,\n\u001b[32m      6\u001b[39m     num_domains=\u001b[32m2\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# atomic_concept_labels=caltech256_labels,\u001b[39;00m\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m domain_A_mapping = domains[\u001b[32m0\u001b[39m].to_mapping()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/master-thesis/project/library/taxonomy.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnx\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyvis\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnetwork\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Network\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     form_correlation_matrix,\n\u001b[32m      9\u001b[39m     foreign_prediction_distributions,\n\u001b[32m     10\u001b[39m     sample_truncated_normal,\n\u001b[32m     11\u001b[39m     hypothesize_relationships,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     15\u001b[39m _RELATIONSHIP_TYPE = Literal[\u001b[33m\"\u001b[39m\u001b[33mmcfp\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mthreshold\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     16\u001b[39m _SYNTHETIC_RELATIONSHIP_TYPE = Literal[\u001b[33m\"\u001b[39m\u001b[33mmcfp\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'foreign_prediction_distributions' from 'library.utils' (/home/sentinel/Development/master-thesis/project/library/utils.py)"
     ]
    }
   ],
   "source": [
    "from library.taxonomy import Taxonomy\n",
    "\n",
    "\n",
    "synthetic_taxonomy, domains = Taxonomy.create_synthetic_taxonomy(\n",
    "    num_atomic_concepts=257,\n",
    "    num_domains=2,\n",
    "    domain_class_count_mean=180,\n",
    "    domain_class_count_variance=10,\n",
    "    concept_cluster_size_mean=3,\n",
    "    concept_cluster_size_variance=1,\n",
    "    has_no_prediction_class=True,\n",
    "    # atomic_concept_labels=caltech256_labels,\n",
    "    relationship_type=\"true\",\n",
    ")\n",
    "\n",
    "domain_A_mapping = domains[0].to_mapping()\n",
    "domain_B_mapping = domains[1].to_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de1034d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/sentinel/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 35/35 [00:08<00:00,  4.05it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8316696882247925\n",
      "        eval_loss           0.7811689972877502\n",
      "        hp_metric           0.8316696882247925\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[{'eval_loss': 0.7811689972877502, 'eval_accuracy': 0.8316696882247925, 'hp_metric': 0.8316696882247925}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from library.models import ResNetModel\n",
    "from library.datasets import Caltech256MappedDataModule\n",
    "\n",
    "\n",
    "# Reduce the precision of matrix multiplication to speed up training\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"logs\", name=\"caltech256_synthetic_A\")\n",
    "dataset = Caltech256MappedDataModule(mapping=domain_A_mapping)\n",
    "model_name = \"resnet50-caltech256-synthetic-A-min-val-loss\"\n",
    "trainer = Trainer(\n",
    "    max_epochs=20,\n",
    "    logger=tb_logger,\n",
    "    callbacks=[\n",
    "        # Save the model with the lowest validation loss\n",
    "        ModelCheckpoint(\n",
    "            dirpath=\"checkpoints\",\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1,\n",
    "            filename=model_name,\n",
    "            enable_version_counter=False,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "TRAIN = False\n",
    "\n",
    "if TRAIN:\n",
    "    model = ResNetModel(\n",
    "        num_classes=len(set(domain_A_mapping.values())),\n",
    "        architecture=\"resnet50\",\n",
    "        optim=\"sgd\",\n",
    "        optim_kwargs={\n",
    "            \"lr\": 0.01,\n",
    "            \"momentum\": 0.9,\n",
    "            \"weight_decay\": 5e-4,\n",
    "        },\n",
    "    )\n",
    "    trainer.fit(model, datamodule=dataset)\n",
    "\n",
    "    # Test with the best model from the checkpoint\n",
    "    results = trainer.test(datamodule=dataset, ckpt_path=\"best\")\n",
    "else:\n",
    "    model = ResNetModel.load_from_checkpoint(f\"checkpoints/{model_name}.ckpt\")\n",
    "    results = trainer.test(model, datamodule=dataset)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19aa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 33/33 [00:08<00:00,  4.09it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8117815852165222\n",
      "        eval_loss           0.7332985997200012\n",
      "        hp_metric           0.8117815852165222\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[{'eval_loss': 0.7332985997200012, 'eval_accuracy': 0.8117815852165222, 'hp_metric': 0.8117815852165222}]\n"
     ]
    }
   ],
   "source": [
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"logs\", name=\"caltech256_synthetic_B\")\n",
    "dataset = Caltech256MappedDataModule(mapping=domain_B_mapping)\n",
    "model_name = \"resnet50-caltech256-synthetic-B-min-val-loss\"\n",
    "trainer = Trainer(\n",
    "    max_epochs=20,\n",
    "    logger=tb_logger,\n",
    "    callbacks=[\n",
    "        # Save the model with the lowest validation loss\n",
    "        ModelCheckpoint(\n",
    "            dirpath=\"checkpoints\",\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1,\n",
    "            filename=model_name,\n",
    "            enable_version_counter=False,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "TRAIN = False\n",
    "\n",
    "if TRAIN:\n",
    "    model = ResNetModel(\n",
    "        architecture=\"resnet50\",\n",
    "        optim=\"sgd\",\n",
    "        optim_kwargs={\n",
    "            \"lr\": 0.01,\n",
    "            \"momentum\": 0.9,\n",
    "            \"weight_decay\": 5e-4,\n",
    "        },\n",
    "        num_classes=len(set(domain_B_mapping.values())),\n",
    "    )\n",
    "    trainer.fit(model, datamodule=dataset)\n",
    "\n",
    "    # Test with the best model from the checkpoint\n",
    "    results = trainer.test(datamodule=dataset, ckpt_path=\"best\")\n",
    "else:\n",
    "    model = ResNetModel.load_from_checkpoint(f\"checkpoints/{model_name}.ckpt\")\n",
    "    results = trainer.test(model, datamodule=dataset)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d34390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchvision.datasets import Caltech256\n",
    "\n",
    "\n",
    "caltech256_labels = Caltech256(root=\"datasets/caltech256\", download=False).categories\n",
    "caltech256_targets = pd.read_csv(\"data/caltech256.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b921137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from library.datasets import Caltech256MappedDataModule\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "\n",
    "PREDICT = False\n",
    "\n",
    "if PREDICT:\n",
    "    dataset_domain_A = Caltech256MappedDataModule(mapping=domain_A_mapping)\n",
    "    model_domain_A = ResNetModel.load_from_checkpoint(\n",
    "        \"checkpoints/resnet50-caltech256-synthetic-A-min-val-loss.ckpt\"\n",
    "    )\n",
    "    model_domain_A.eval()\n",
    "\n",
    "    dataset_domain_B = Caltech256MappedDataModule(mapping=domain_B_mapping)\n",
    "    model_domain_B = ResNetModel.load_from_checkpoint(\n",
    "        \"checkpoints/resnet50-caltech256-synthetic-B-min-val-loss.ckpt\"\n",
    "    )\n",
    "    model_domain_B.eval()\n",
    "\n",
    "    trainer = Trainer(logger=False, enable_checkpointing=False)\n",
    "    model_A_on_domain_B = trainer.predict(model_domain_A, datamodule=dataset_domain_B)\n",
    "    model_B_on_domain_A = trainer.predict(model_domain_B, datamodule=dataset_domain_A)\n",
    "\n",
    "    predictions_A_on_B = torch.cat(model_A_on_domain_B).argmax(dim=1)  # type: ignore\n",
    "    predictions_B_on_A = torch.cat(model_B_on_domain_A).argmax(dim=1)  # type: ignore\n",
    "\n",
    "    domain_A_targets = torch.cat(\n",
    "        [label for _, label in dataset_domain_A.predict_dataloader()]\n",
    "    )\n",
    "    domain_A_targets = domain_A_targets.map_(\n",
    "        torch.zeros_like(domain_A_targets), lambda x, _: domain_A_mapping[x]\n",
    "    )\n",
    "    domain_B_targets = torch.cat(\n",
    "        [label for _, label in dataset_domain_B.predict_dataloader()]\n",
    "    )\n",
    "    domain_B_targets = domain_B_targets.map_(\n",
    "        torch.zeros_like(domain_B_targets), lambda x, _: domain_B_mapping[x]\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"domain_A\": domain_A_targets,\n",
    "            \"predictions_B_on_A\": predictions_B_on_A,\n",
    "        }\n",
    "    )\n",
    "    df.to_csv(\"data/caltech256_domain_A_predictions.csv\", index=False)\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"domain_B\": domain_B_targets,\n",
    "            \"predictions_A_on_B\": predictions_A_on_B,\n",
    "        }\n",
    "    )\n",
    "    df.to_csv(\"data/caltech256_domain_B_predictions.csv\", index=False)\n",
    "\n",
    "df_A = pd.read_csv(\"data/caltech256_domain_A_predictions.csv\")\n",
    "df_B = pd.read_csv(\"data/caltech256_domain_B_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e6288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.taxonomy import Taxonomy\n",
    "import numpy as np\n",
    "\n",
    "taxonomy = Taxonomy.from_cross_domain_predictions(\n",
    "    cross_domain_predictions=[\n",
    "        (0, 1, np.array(df_B[\"predictions_A_on_B\"], dtype=np.intp)),\n",
    "        (1, 0, np.array(df_A[\"predictions_B_on_A\"], dtype=np.intp)),\n",
    "    ],\n",
    "    domain_targets=[\n",
    "        (0, np.array(df_A[\"domain_A\"], dtype=np.intp)),\n",
    "        (1, np.array(df_B[\"domain_B\"], dtype=np.intp)),\n",
    "    ],\n",
    "    domain_labels=synthetic_taxonomy.domain_labels,\n",
    "    relationship_type=\"mcfp\",\n",
    ")\n",
    "taxonomy.visualize_graph(\"Synthetic Model Taxonomy\").save_graph(\n",
    "    \"output/caltech256_synthetic_model_taxonomy.html\"\n",
    ")\n",
    "taxonomy.build_universal_taxonomy()\n",
    "taxonomy.visualize_graph(\"Synthetic Model Universal Taxonomy\").save_graph(\n",
    "    \"output/caltech256_synthetic_model_universal_taxonomy.html\"\n",
    ")\n",
    "\n",
    "synthetic_taxonomy.visualize_graph(\"Synthetic Taxonomy\").save_graph(\n",
    "    \"output/caltech256_synthetic_taxonomy.html\"\n",
    ")\n",
    "synthetic_taxonomy.build_universal_taxonomy()\n",
    "synthetic_taxonomy.visualize_graph(\"Synthetic Universal Taxonomy\").save_graph(\n",
    "    \"output/caltech256_synthetic_universal_taxonomy.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d503b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "edr = taxonomy.edge_difference_ratio(synthetic_taxonomy, weighted=True)\n",
    "rmse = taxonomy.rmse(synthetic_taxonomy, weighted=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
