{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "644c71a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caltech-256 classes: 257\n",
      "Caltech-101 classes: 101\n",
      "CIFAR-100 classes: 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import Caltech256, Caltech101, CIFAR100\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "\n",
    "from library.taxonomy import Taxonomy\n",
    "from library.models import UniversalEfficientNetV2Model\n",
    "from library.datasets import (\n",
    "    Caltech256DataModule,\n",
    "    Caltech101DataModule,\n",
    "    CIFAR100ScaledDataModule,\n",
    "    CombinedDataModule,\n",
    ")\n",
    "\n",
    "# Load dataset information\n",
    "caltech256_labels = Caltech256(root=\"datasets/caltech256\", download=False).categories\n",
    "caltech101_labels = Caltech101(root=\"datasets/caltech101\", download=False).categories\n",
    "cifar100_labels = CIFAR100(\n",
    "    root=\"datasets/cifar100\", download=False, train=False\n",
    ").classes\n",
    "\n",
    "print(f\"Caltech-256 classes: {len(caltech256_labels)}\")\n",
    "print(f\"Caltech-101 classes: {len(caltech101_labels)}\")\n",
    "print(f\"CIFAR-100 classes: {len(cifar100_labels)}\")\n",
    "\n",
    "# Reduce the precision of matrix multiplication to speed up training\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a1b20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded three-domain MCFP taxonomy with 1244 nodes\n",
      "Universal classes: 82\n",
      "Domain classes: 1162\n"
     ]
    }
   ],
   "source": [
    "# Load the three-domain MCFP taxonomy\n",
    "three_domain_mcfp_taxonomy = Taxonomy.load(\"taxonomies/three_domain_mcfp.pkl\")\n",
    "\n",
    "print(\n",
    "    f\"Loaded three-domain MCFP taxonomy with {len(three_domain_mcfp_taxonomy.get_nodes())} nodes\"\n",
    ")\n",
    "print(\n",
    "    f\"Universal classes: {len([node for node in three_domain_mcfp_taxonomy.get_nodes() if hasattr(node, '__len__') and len(node) == 1])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Domain classes: {len([node for node in three_domain_mcfp_taxonomy.get_nodes() if hasattr(node, '__len__') and len(node) == 2])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17cf7e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset modules created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create individual dataset modules\n",
    "caltech101_dm = Caltech101DataModule(batch_size=16)\n",
    "caltech256_dm = Caltech256DataModule(batch_size=16)\n",
    "cifar100_dm = CIFAR100ScaledDataModule(batch_size=16)\n",
    "\n",
    "# Create three-domain data module\n",
    "# Domain 0: Caltech-101, Domain 1: Caltech-256, Domain 2: CIFAR-100\n",
    "three_domain_dataset_module = CombinedDataModule(\n",
    "    dataset_modules=[caltech101_dm, caltech256_dm, cifar100_dm],\n",
    "    domain_ids=[0, 1, 2],\n",
    "    batch_size=32,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "print(\"Dataset modules created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed1408df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration set for EfficientNetV2-S with three-domain MCFP taxonomy\n"
     ]
    }
   ],
   "source": [
    "# Training configuration for EfficientNetV2\n",
    "TRAIN = False  # Set to True to train model from scratch\n",
    "EFFICIENTNET_VARIANT = (\n",
    "    \"s\"  # EfficientNet variant: \"s\" (Small), \"m\" (Medium), \"l\" (Large)\n",
    ")\n",
    "\n",
    "training_config = {\n",
    "    \"max_epochs\": 50,\n",
    "    \"optim\": \"adamw\",\n",
    "    \"optim_kwargs\": {\n",
    "        \"lr\": 0.00003,  # Slightly lower learning rate for EfficientNet\n",
    "        \"weight_decay\": 0.001,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"eps\": 1e-8,\n",
    "    },\n",
    "    \"lr_scheduler\": \"cosine\",\n",
    "    \"lr_scheduler_kwargs\": {\n",
    "        \"T_max\": 50,  # matches max_epochs\n",
    "        \"eta_min\": 1e-7,\n",
    "    },\n",
    "}\n",
    "\n",
    "model_name = (\n",
    "    f\"universal-efficientnetv2-{EFFICIENTNET_VARIANT}-three-domain-mcfp-min-val-loss\"\n",
    ")\n",
    "logger_name = f\"universal_efficientnetv2_{EFFICIENTNET_VARIANT}_three_domain_mcfp\"\n",
    "\n",
    "print(\n",
    "    f\"Training configuration set for EfficientNetV2-{EFFICIENTNET_VARIANT.upper()} with three-domain MCFP taxonomy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd422d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training disabled. Set TRAIN=True to start training.\n"
     ]
    }
   ],
   "source": [
    "# Create the Universal EfficientNetV2 model\n",
    "model = UniversalEfficientNetV2Model(\n",
    "    taxonomy=three_domain_mcfp_taxonomy,\n",
    "    optim=training_config[\"optim\"],\n",
    "    optim_kwargs=training_config[\"optim_kwargs\"],\n",
    "    lr_scheduler=training_config[\"lr_scheduler\"],\n",
    "    lr_scheduler_kwargs=training_config[\"lr_scheduler_kwargs\"],\n",
    "    efficientnet_variant=EFFICIENTNET_VARIANT,\n",
    ")\n",
    "\n",
    "\n",
    "# Setup trainer\n",
    "if TRAIN:\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"logs\", name=logger_name)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=training_config[\"max_epochs\"],\n",
    "        logger=tb_logger,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                dirpath=\"checkpoints\",\n",
    "                monitor=\"val_accuracy\",\n",
    "                mode=\"max\",\n",
    "                save_top_k=1,\n",
    "                filename=model_name,\n",
    "                enable_version_counter=False,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    # Train the model\n",
    "    trainer.fit(model, datamodule=three_domain_dataset_module)\n",
    "\n",
    "    # Test the trained model\n",
    "    print(\"Training completed. Running final test...\")\n",
    "    test_results = trainer.test(\n",
    "        datamodule=three_domain_dataset_module, ckpt_path=\"best\"\n",
    "    )\n",
    "\n",
    "    print(f\"Final test accuracy: {test_results[0]['eval_accuracy']:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Training disabled. Set TRAIN=True to start training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b086235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: universal-efficientnetv2-s-three-domain-mcfp-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on individual domains...\n",
      "Testing DataLoader 0:  14%|█▍        | 2/14 [00:00<00:04,  2.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:02<00:00,  6.71it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9446367025375366\n",
      "        eval_loss            2.548962116241455\n",
      "        hp_metric           0.9446367025375366\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9446367025375366\n",
      "        eval_loss            2.548962116241455\n",
      "        hp_metric           0.9446367025375366\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 48/48 [00:05<00:00,  8.01it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8970588445663452\n",
      "        eval_loss           2.1533899307250977\n",
      "        hp_metric           0.8970588445663452\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8970588445663452\n",
      "        eval_loss           2.1533899307250977\n",
      "        hp_metric           0.8970588445663452\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 52. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:17<00:00,  9.00it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8772000074386597\n",
      "        eval_loss           1.5989248752593994\n",
      "        hp_metric           0.8772000074386597\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8772000074386597\n",
      "        eval_loss           1.5989248752593994\n",
      "        hp_metric           0.8772000074386597\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   1%|          | 3/436 [00:00<00:58,  7.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 436/436 [00:31<00:00, 13.97it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8856178522109985\n",
      "        eval_loss            1.77834951877594\n",
      "        hp_metric           0.8856178522109985\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8856178522109985\n",
      "        eval_loss            1.77834951877594\n",
      "        hp_metric           0.8856178522109985\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 7. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EfficientNetV2-S Universal Model Results ===\n",
      "Caltech-101 accuracy: 0.9446 (94.46%)\n",
      "Caltech-256 accuracy: 0.8971 (89.71%)\n",
      "CIFAR-100 accuracy: 0.8772 (87.72%)\n",
      "Combined accuracy: 0.8856 (88.56%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on individual domains\n",
    "if not TRAIN:\n",
    "    # Load pre-trained model for evaluation\n",
    "    print(f\"Loading pre-trained model: {model_name}.ckpt\")\n",
    "    model = UniversalEfficientNetV2Model.load_from_checkpoint(\n",
    "        f\"checkpoints/{model_name}.ckpt\",\n",
    "        taxonomy=three_domain_mcfp_taxonomy,\n",
    "        efficientnet_variant=EFFICIENTNET_VARIANT,\n",
    "    )\n",
    "\n",
    "# Create individual combined data modules for each domain\n",
    "caltech101_combined_dm = CombinedDataModule(\n",
    "    dataset_modules=[caltech101_dm],\n",
    "    domain_ids=[0],  # Domain 0 for Caltech-101\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "caltech256_combined_dm = CombinedDataModule(\n",
    "    dataset_modules=[caltech256_dm],\n",
    "    domain_ids=[1],  # Domain 1 for Caltech-256\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "cifar100_combined_dm = CombinedDataModule(\n",
    "    dataset_modules=[cifar100_dm],\n",
    "    domain_ids=[2],  # Domain 2 for CIFAR-100\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "# Create trainer for testing\n",
    "test_trainer = Trainer(\n",
    "    logger=False,\n",
    "    enable_checkpointing=False,\n",
    ")\n",
    "\n",
    "print(\"Evaluating on individual domains...\")\n",
    "\n",
    "# Test on Caltech-101 (Domain 0)\n",
    "caltech101_results = test_trainer.test(model, datamodule=caltech101_combined_dm)\n",
    "caltech101_accuracy = caltech101_results[0][\"eval_accuracy\"]\n",
    "\n",
    "# Test on Caltech-256 (Domain 1)\n",
    "caltech256_results = test_trainer.test(model, datamodule=caltech256_combined_dm)\n",
    "caltech256_accuracy = caltech256_results[0][\"eval_accuracy\"]\n",
    "\n",
    "# Test on CIFAR-100 (Domain 2)\n",
    "cifar100_results = test_trainer.test(model, datamodule=cifar100_combined_dm)\n",
    "cifar100_accuracy = cifar100_results[0][\"eval_accuracy\"]\n",
    "\n",
    "# Test on all three domains combined\n",
    "combined_results = test_trainer.test(model, datamodule=three_domain_dataset_module)\n",
    "combined_accuracy = combined_results[0][\"eval_accuracy\"]\n",
    "\n",
    "print(\n",
    "    f\"\\n=== EfficientNetV2-{EFFICIENTNET_VARIANT.upper()} Universal Model Results ===\"\n",
    ")\n",
    "print(\n",
    "    f\"Caltech-101 accuracy: {caltech101_accuracy:.4f} ({caltech101_accuracy*100:.2f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"Caltech-256 accuracy: {caltech256_accuracy:.4f} ({caltech256_accuracy*100:.2f}%)\"\n",
    ")\n",
    "print(f\"CIFAR-100 accuracy: {cifar100_accuracy:.4f} ({cifar100_accuracy*100:.2f}%)\")\n",
    "print(f\"Combined accuracy: {combined_accuracy:.4f} ({combined_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Store results for comparison\n",
    "efficientnet_results = {\n",
    "    \"model\": f\"UniversalEfficientNetV2-{EFFICIENTNET_VARIANT.upper()}\",\n",
    "    \"taxonomy\": \"Three-Domain MCFP\",\n",
    "    \"caltech101\": caltech101_accuracy,\n",
    "    \"caltech256\": caltech256_accuracy,\n",
    "    \"cifar100\": cifar100_accuracy,\n",
    "    \"combined\": combined_accuracy,\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
