{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9529cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Country211 classes: 211\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "\n",
    "from library.taxonomy_constructors import SyntheticTaxonomy, CrossPredictionsTaxonomy\n",
    "from library.models import ResNetModel\n",
    "from library.datasets import Country211MappedDataModule, Country211Mapped\n",
    "\n",
    "# Load Country211 dataset information\n",
    "country211_dataset = Country211Mapped(root=\"datasets\", download=False)\n",
    "country211_labels = country211_dataset.classes\n",
    "print(f\"Total Country211 classes: {len(country211_labels)}\")\n",
    "\n",
    "# Create a simple target mapping for Country211 (0 to num_classes-1)\n",
    "country211_targets = pd.DataFrame(\n",
    "    {\"class_id\": range(len(country211_labels)), \"class_name\": country211_labels}\n",
    ")\n",
    "\n",
    "# Reduce the precision of matrix multiplication to speed up training\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebf4092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain A classes: 52\n",
      "Domain B classes: 49\n",
      "Domain A original classes: 152\n",
      "Domain B original classes: 152\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic taxonomy with 2 domains for Country211\n",
    "synthetic_taxonomy = SyntheticTaxonomy.create_synthetic_taxonomy(\n",
    "    num_atomic_concepts=len(country211_labels),\n",
    "    num_domains=2,\n",
    "    domain_class_count_mean=150,  # Adjusted for Country211's 211 classes\n",
    "    domain_class_count_variance=10,\n",
    "    concept_cluster_size_mean=3,\n",
    "    concept_cluster_size_variance=1,\n",
    "    no_prediction_class=True,\n",
    "    atomic_concept_labels=country211_labels,\n",
    "    relationship_type=\"true\",\n",
    ")\n",
    "\n",
    "# Extract domain mappings\n",
    "domain_A_mapping = synthetic_taxonomy.domains[0].to_mapping()\n",
    "domain_B_mapping = synthetic_taxonomy.domains[1].to_mapping()\n",
    "\n",
    "print(f\"Domain A classes: {len(set(domain_A_mapping.values()))}\")\n",
    "print(f\"Domain B classes: {len(set(domain_B_mapping.values()))}\")\n",
    "print(f\"Domain A original classes: {len(domain_A_mapping)}\")\n",
    "print(f\"Domain B original classes: {len(domain_B_mapping)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87f25df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "TRAIN = True  # Set to True to train models from scratch\n",
    "\n",
    "\n",
    "def train_domain_model(domain_mapping, domain_name, logger_name, model_name):\n",
    "    \"\"\"Train a ResNet model for a specific domain using Country211\"\"\"\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"logs\", name=logger_name)\n",
    "    dataset = Country211MappedDataModule(mapping=domain_mapping, split=\"train\")\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=60,\n",
    "        logger=tb_logger if TRAIN else False,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                dirpath=\"checkpoints\",\n",
    "                monitor=\"val_loss\",\n",
    "                mode=\"min\",\n",
    "                save_top_k=1,\n",
    "                filename=model_name,\n",
    "                enable_version_counter=False,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    if TRAIN:\n",
    "        model = ResNetModel(\n",
    "            num_classes=len(set(domain_mapping.values())),\n",
    "            architecture=\"resnet50\",\n",
    "            optim=\"sgd\",\n",
    "            optim_kwargs={\n",
    "                \"lr\": 0.01,\n",
    "                \"momentum\": 0.9,\n",
    "                \"weight_decay\": 5e-4,\n",
    "            },\n",
    "        )\n",
    "        trainer.fit(model, datamodule=dataset)\n",
    "        results = trainer.test(datamodule=dataset, ckpt_path=\"best\")\n",
    "    else:\n",
    "        model = ResNetModel.load_from_checkpoint(f\"checkpoints/{model_name}.ckpt\")\n",
    "        results = trainer.test(model, datamodule=dataset)\n",
    "\n",
    "    print(f\"{domain_name} Results: {results}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae14c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Testing Domain A Model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/sentinel/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 357/357 [01:50<00:00,  3.24it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8900877237319946\n",
      "        eval_loss           0.3789011836051941\n",
      "        hp_metric           0.8900877237319946\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Domain A Results: [{'eval_loss': 0.3789011836051941, 'eval_accuracy': 0.8900877237319946, 'hp_metric': 0.8900877237319946}]\n"
     ]
    }
   ],
   "source": [
    "# Train Domain A model\n",
    "print(\"Training/Testing Domain A Model:\")\n",
    "domain_A_results = train_domain_model(\n",
    "    domain_A_mapping,\n",
    "    \"Domain A\",\n",
    "    \"country211_synthetic_A\",\n",
    "    \"resnet50-country211-synthetic-A-min-val-loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e3fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Testing Domain B Model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sentinel/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/sentinel/Development/master-thesis/project/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | ResNet           | 26.3 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "26.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "26.3 M    Total params\n",
      "105.206   Total estimated model params size (MB)\n",
      "162       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sentinel/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sentinel/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:   7%|▋         | 25/357 [00:09<02:02,  2.71it/s, v_num=2] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/loops/training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/loops/training_epoch_loop.py:282\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    281\u001b[39m dataloader_iter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m batch, _, __ = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/loops/fetchers.py:134\u001b[39m, in \u001b[36m_PrefetchDataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     batch = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/loops/fetchers.py:61\u001b[39m, in \u001b[36m_DataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/combined_loader.py:341\u001b[39m, in \u001b[36mCombinedLoader.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m out = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator, _Sequential):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/combined_loader.py:78\u001b[39m, in \u001b[36m_MaxSizeCycle.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     out[i] = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    763\u001b[39m index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/master-thesis/project/library/datasets.py:411\u001b[39m, in \u001b[36mCountry211Mapped.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     sample = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/torchvision/transforms/v2/_container.py:51\u001b[39m, in \u001b[36mCompose.forward\u001b[39m\u001b[34m(self, *inputs)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     outputs = \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     inputs = outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/torchvision/transforms/v2/_transform.py:69\u001b[39m, in \u001b[36mTransform.forward\u001b[39m\u001b[34m(self, *inputs)\u001b[39m\n\u001b[32m     64\u001b[39m params = \u001b[38;5;28mself\u001b[39m.make_params(\n\u001b[32m     65\u001b[39m     [inpt \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[38;5;28;01mif\u001b[39;00m needs_transform]\n\u001b[32m     66\u001b[39m )\n\u001b[32m     68\u001b[39m flat_outputs = [\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m needs_transform \u001b[38;5;28;01melse\u001b[39;00m inpt\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[32m     71\u001b[39m ]\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/torchvision/transforms/v2/_type_conversion.py:39\u001b[39m, in \u001b[36mToImage.transform\u001b[39m\u001b[34m(self, inpt, params)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mself\u001b[39m, inpt: Union[torch.Tensor, PIL.Image.Image, np.ndarray], params: Dict[\u001b[38;5;28mstr\u001b[39m, Any]\n\u001b[32m     38\u001b[39m ) -> tv_tensors.Image:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/torchvision/transforms/v2/functional/_type_conversion.py:16\u001b[39m, in \u001b[36mto_image\u001b[39m\u001b[34m(inpt)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inpt, PIL.Image.Image):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     output = \u001b[43mpil_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inpt, torch.Tensor):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/torchvision/transforms/functional.py:209\u001b[39m, in \u001b[36mpil_to_tensor\u001b[39m\u001b[34m(pic)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m img = torch.as_tensor(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[32m    210\u001b[39m img = img.view(pic.size[\u001b[32m1\u001b[39m], pic.size[\u001b[32m0\u001b[39m], F_pil.get_image_num_channels(pic))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/PIL/Image.py:756\u001b[39m, in \u001b[36mImage.__array_interface__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m756\u001b[39m     new[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    757\u001b[39m new[\u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m], new[\u001b[33m\"\u001b[39m\u001b[33mtypestr\u001b[39m\u001b[33m\"\u001b[39m] = _conv_type_shape(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/PIL/Image.py:818\u001b[39m, in \u001b[36mImage.tobytes\u001b[39m\u001b[34m(self, encoder_name, *args)\u001b[39m\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m     bytes_consumed, errcode, data = \u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    819\u001b[39m     output.append(data)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Train Domain B model\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining/Testing Domain B Model:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m domain_B_results = \u001b[43mtrain_domain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdomain_B_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDomain B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcountry211_synthetic_B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresnet50-country211-synthetic-B-min-val-loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mtrain_domain_model\u001b[39m\u001b[34m(domain_mapping, domain_name, logger_name, model_name)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TRAIN:\n\u001b[32m     26\u001b[39m     model = ResNetModel(\n\u001b[32m     27\u001b[39m         num_classes=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(domain_mapping.values())),\n\u001b[32m     28\u001b[39m         architecture=\u001b[33m\"\u001b[39m\u001b[33mresnet50\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m         },\n\u001b[32m     35\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     results = trainer.test(datamodule=dataset, ckpt_path=\u001b[33m\"\u001b[39m\u001b[33mbest\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "# Train Domain B model\n",
    "print(\"Training/Testing Domain B Model:\")\n",
    "domain_B_results = train_domain_model(\n",
    "    domain_B_mapping,\n",
    "    \"Domain B\",\n",
    "    \"country211_synthetic_B\",\n",
    "    \"resnet50-country211-synthetic-B-min-val-loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f6e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/sentinel/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/sentinel/.conda/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating cross-domain predictions...\n",
      "Predicting DataLoader 0: 100%|██████████| 238/238 [01:24<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 238/238 [01:18<00:00,  3.03it/s]\n",
      "\n",
      "Predictions saved to CSV files.\n",
      "Domain A predictions shape: (15200, 2)\n",
      "Domain B predictions shape: (15200, 2)\n",
      "Predictions saved to CSV files.\n",
      "Domain A predictions shape: (15200, 2)\n",
      "Domain B predictions shape: (15200, 2)\n"
     ]
    }
   ],
   "source": [
    "# Configuration for prediction generation\n",
    "PREDICT = True  # Set to True to generate predictions from scratch\n",
    "\n",
    "if PREDICT:\n",
    "    # Load datasets\n",
    "    dataset_domain_A = Country211MappedDataModule(\n",
    "        mapping=domain_A_mapping, split=\"test\"\n",
    "    )\n",
    "    dataset_domain_B = Country211MappedDataModule(\n",
    "        mapping=domain_B_mapping, split=\"test\"\n",
    "    )\n",
    "\n",
    "    # Load trained models\n",
    "    model_domain_A = ResNetModel.load_from_checkpoint(\n",
    "        \"checkpoints/resnet50-country211-synthetic-A-min-val-loss.ckpt\"\n",
    "    )\n",
    "    model_domain_A.eval()\n",
    "\n",
    "    model_domain_B = ResNetModel.load_from_checkpoint(\n",
    "        \"checkpoints/resnet50-country211-synthetic-B-min-val-loss.ckpt\"\n",
    "    )\n",
    "    model_domain_B.eval()\n",
    "\n",
    "    trainer = Trainer(logger=False, enable_checkpointing=False)\n",
    "\n",
    "    # Generate cross-domain predictions\n",
    "    print(\"Generating cross-domain predictions...\")\n",
    "    model_A_on_domain_B = trainer.predict(model_domain_A, datamodule=dataset_domain_B)\n",
    "    model_B_on_domain_A = trainer.predict(model_domain_B, datamodule=dataset_domain_A)\n",
    "\n",
    "    # Convert predictions to class indices\n",
    "    predictions_A_on_B = torch.cat(model_A_on_domain_B).argmax(dim=1)  # type: ignore\n",
    "    predictions_B_on_A = torch.cat(model_B_on_domain_A).argmax(dim=1)  # type: ignore\n",
    "\n",
    "    # Get ground truth targets\n",
    "    domain_A_targets = torch.cat(\n",
    "        [label for _, label in dataset_domain_A.predict_dataloader()]\n",
    "    )\n",
    "    domain_B_targets = torch.cat(\n",
    "        [label for _, label in dataset_domain_B.predict_dataloader()]\n",
    "    )\n",
    "\n",
    "    # Save predictions\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"domain_A\": domain_A_targets,\n",
    "            \"predictions_B_on_A\": predictions_B_on_A,\n",
    "        }\n",
    "    ).to_csv(\"data/country211_2domain_A_predictions.csv\", index=False)\n",
    "\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"domain_B\": domain_B_targets,\n",
    "            \"predictions_A_on_B\": predictions_A_on_B,\n",
    "        }\n",
    "    ).to_csv(\"data/country211_2domain_B_predictions.csv\", index=False)\n",
    "\n",
    "    print(\"Predictions saved to CSV files.\")\n",
    "\n",
    "# Load prediction results\n",
    "df_A = pd.read_csv(\"data/country211_2domain_A_predictions.csv\")\n",
    "df_B = pd.read_csv(\"data/country211_2domain_B_predictions.csv\")\n",
    "\n",
    "print(f\"Domain A predictions shape: {df_A.shape}\")\n",
    "print(f\"Domain B predictions shape: {df_B.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce16940c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxonomy constructed from cross-domain predictions.\n"
     ]
    }
   ],
   "source": [
    "# Construct taxonomy from cross-domain predictions\n",
    "taxonomy = CrossPredictionsTaxonomy.from_cross_domain_predictions(\n",
    "    cross_domain_predictions=[\n",
    "        (0, 1, np.array(df_B[\"predictions_A_on_B\"], dtype=np.intp)),\n",
    "        (1, 0, np.array(df_A[\"predictions_B_on_A\"], dtype=np.intp)),\n",
    "    ],\n",
    "    domain_targets=[\n",
    "        (0, np.array(df_A[\"domain_A\"], dtype=np.intp)),\n",
    "        (1, np.array(df_B[\"domain_B\"], dtype=np.intp)),\n",
    "    ],\n",
    "    domain_labels=synthetic_taxonomy.domain_labels,\n",
    "    relationship_type=\"hypothesis\",\n",
    ")\n",
    "\n",
    "print(\"Taxonomy constructed from cross-domain predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec30331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating taxonomy visualizations...\n",
      "Taxonomy visualizations saved to output/ directory.\n"
     ]
    }
   ],
   "source": [
    "# Generate and save taxonomy visualizations\n",
    "print(\"Generating taxonomy visualizations...\")\n",
    "\n",
    "taxonomy.visualize_graph(\"2-Domain Country211 Model Taxonomy\").save_graph(\n",
    "    \"output/country211_2domain_synthetic_model_taxonomy.html\"\n",
    ")\n",
    "\n",
    "synthetic_taxonomy.visualize_graph(\n",
    "    \"2-Domain Country211 Ground Truth Taxonomy\"\n",
    ").save_graph(\"output/country211_2domain_synthetic_taxonomy.html\")\n",
    "\n",
    "print(\"Taxonomy visualizations saved to output/ directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-Domain Country211 Taxonomy Evaluation:\n",
      "Edge Difference Ratio: 0.9771\n",
      "Precision: 0.0396\n",
      "Recall: 0.0179\n",
      "F1 Score: 0.0246\n"
     ]
    }
   ],
   "source": [
    "# Evaluate taxonomy against ground truth\n",
    "edr = taxonomy.edge_difference_ratio(synthetic_taxonomy)\n",
    "precision, recall, f1 = taxonomy.precision_recall_f1(synthetic_taxonomy)\n",
    "\n",
    "print(\"2-Domain Country211 Taxonomy Evaluation:\")\n",
    "print(f\"Edge Difference Ratio: {edr:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdf6947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building universal taxonomies...\n",
      "Universal taxonomy visualizations saved to output/ directory.\n",
      "Universal taxonomy visualizations saved to output/ directory.\n"
     ]
    }
   ],
   "source": [
    "# Build universal taxonomies\n",
    "print(\"Building universal taxonomies...\")\n",
    "\n",
    "taxonomy.build_universal_taxonomy()\n",
    "taxonomy.visualize_graph(\"2-Domain Country211 Model Universal Taxonomy\").save_graph(\n",
    "    \"output/country211_2domain_synthetic_model_universal_taxonomy.html\"\n",
    ")\n",
    "\n",
    "synthetic_taxonomy.build_universal_taxonomy()\n",
    "synthetic_taxonomy.visualize_graph(\n",
    "    \"2-Domain Country211 Ground Truth Universal Taxonomy\"\n",
    ").save_graph(\"output/country211_2domain_synthetic_universal_taxonomy.html\")\n",
    "\n",
    "print(\"Universal taxonomy visualizations saved to output/ directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
