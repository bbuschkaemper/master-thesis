{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249d7fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caltech-256 classes: 257\n",
      "Caltech-101 classes: 101\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import Caltech256, Caltech101\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "\n",
    "from library.taxonomy import Taxonomy\n",
    "from library.models import UniversalResNetModel\n",
    "from library.datasets import (\n",
    "    Caltech256DataModule,\n",
    "    Caltech101DataModule,\n",
    "    CombinedDataModule,\n",
    ")\n",
    "\n",
    "# Load dataset information\n",
    "caltech256_labels = Caltech256(root=\"datasets/caltech256\", download=False).categories\n",
    "caltech101_labels = Caltech101(root=\"datasets/caltech101\", download=False).categories\n",
    "\n",
    "print(f\"Caltech-256 classes: {len(caltech256_labels)}\")\n",
    "print(f\"Caltech-101 classes: {len(caltech101_labels)}\")\n",
    "\n",
    "# Reduce the precision of matrix multiplication to speed up training\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25714df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both taxonomies created from the real-world datasets\n",
    "hypothesis_taxonomy = Taxonomy.load(\"taxonomies/caltech256_caltech101_hypothesis.pkl\")\n",
    "mcfp_taxonomy = Taxonomy.load(\"taxonomies/caltech256_caltech101_mcfp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a9cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Multi-Domain Training\n",
    "\n",
    "# Training configuration\n",
    "TRAIN = False  # Set to True to train model from scratch\n",
    "\n",
    "# Create individual dataset modules\n",
    "caltech101_dm = Caltech101DataModule(batch_size=32)\n",
    "caltech256_dm = Caltech256DataModule(batch_size=32)\n",
    "\n",
    "# Create combined data module with domain IDs\n",
    "# Domain 0: Caltech-101, Domain 1: Caltech-256\n",
    "dataset_module = CombinedDataModule(\n",
    "    dataset_modules=[caltech101_dm, caltech256_dm],\n",
    "    domain_ids=[0, 1],\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "dataset_name = \"Caltech-101 + Caltech-256 (Multi-Domain)\"\n",
    "\n",
    "# Configuration for both taxonomies\n",
    "taxonomies_config = {\n",
    "    \"hypothesis\": {\n",
    "        \"taxonomy\": hypothesis_taxonomy,\n",
    "        \"model_name\": \"universal-resnet50-hypothesis-multi-domain-min-val-loss\",\n",
    "        \"logger_name\": \"universal_hypothesis_multi_domain\",\n",
    "    },\n",
    "    \"mcfp\": {\n",
    "        \"taxonomy\": mcfp_taxonomy,\n",
    "        \"model_name\": \"universal-resnet50-mcfp-multi-domain-min-val-loss\",\n",
    "        \"logger_name\": \"universal_mcfp_multi_domain\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0c7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration (shared for both models)\n",
    "training_config = {\n",
    "    \"max_epochs\": 50,\n",
    "    \"optim\": \"adamw\",\n",
    "    \"optim_kwargs\": {\n",
    "        \"lr\": 0.00005,  # Reduced from 0.0001\n",
    "        \"weight_decay\": 0.001,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"eps\": 1e-8,\n",
    "    },\n",
    "    \"lr_scheduler\": \"cosine\",  # Changed from multistep\n",
    "    \"lr_scheduler_kwargs\": {\n",
    "        \"T_max\": 50,  # matches max_epochs\n",
    "        \"eta_min\": 1e-7,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2e34cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: universal-resnet50-hypothesis-multi-domain-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   3%|▎         | 2/62 [00:01<00:51,  1.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 62/62 [00:09<00:00,  6.75it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy          0.840081512928009\n",
      "        eval_loss           2.2472734451293945\n",
      "        hp_metric            0.840081512928009\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 23. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/bjoern/dev/master-thesis/project/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | ResNet           | 26.0 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "26.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "26.0 M    Total params\n",
      "103.893   Total estimated model params size (MB)\n",
      "154       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 492/492 [02:29<00:00,  3.30it/s, v_num=4]       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 492/492 [02:29<00:00,  3.30it/s, v_num=4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/bjoern/dev/master-thesis/project/checkpoints/universal-resnet50-mcfp-multi-domain-min-val-loss.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/bjoern/dev/master-thesis/project/checkpoints/universal-resnet50-mcfp-multi-domain-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 62/62 [00:10<00:00,  5.93it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8230201005935669\n",
      "        eval_loss           1.6218763589859009\n",
      "        hp_metric           0.8230201005935669\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# Train models for both taxonomies\n",
    "results = {}\n",
    "\n",
    "for taxonomy_name, config in taxonomies_config.items():\n",
    "    # Create the Universal ResNet model for this taxonomy\n",
    "    model = UniversalResNetModel(\n",
    "        taxonomy=config[\"taxonomy\"],\n",
    "        architecture=\"resnet50\",\n",
    "        optim=training_config[\"optim\"],\n",
    "        optim_kwargs=training_config[\"optim_kwargs\"],\n",
    "        lr_scheduler=training_config[\"lr_scheduler\"],\n",
    "        lr_scheduler_kwargs=training_config[\"lr_scheduler_kwargs\"],\n",
    "    )\n",
    "\n",
    "    # Setup trainer\n",
    "    if TRAIN:\n",
    "        tb_logger = pl_loggers.TensorBoardLogger(\n",
    "            save_dir=\"logs\", name=config[\"logger_name\"]\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            max_epochs=training_config[\"max_epochs\"],\n",
    "            logger=tb_logger,\n",
    "            callbacks=[\n",
    "                ModelCheckpoint(\n",
    "                    dirpath=\"checkpoints\",\n",
    "                    monitor=\"val_accuracy\",\n",
    "                    mode=\"max\",\n",
    "                    save_top_k=1,\n",
    "                    filename=config[\"model_name\"],\n",
    "                    enable_version_counter=False,\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.fit(model, datamodule=dataset_module)\n",
    "\n",
    "        # Test the trained model\n",
    "        test_results = trainer.test(datamodule=dataset_module, ckpt_path=\"best\")\n",
    "\n",
    "    else:\n",
    "        trainer = Trainer(\n",
    "            logger=False,\n",
    "            enable_checkpointing=False,\n",
    "        )\n",
    "\n",
    "        # Load pre-trained model\n",
    "        print(f\"Loading pre-trained model: {config['model_name']}.ckpt\")\n",
    "        model = UniversalResNetModel.load_from_checkpoint(\n",
    "            f\"checkpoints/{config['model_name']}.ckpt\",\n",
    "            taxonomy=config[\n",
    "                \"taxonomy\"\n",
    "            ],  # Need to pass taxonomy since it's not serialized\n",
    "        )\n",
    "\n",
    "        # Test the loaded model\n",
    "        test_results = trainer.test(model, datamodule=dataset_module)\n",
    "\n",
    "    # Store results\n",
    "    results[taxonomy_name] = test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103b2c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: universal-resnet50-hypothesis-multi-domain-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:01<00:00,  8.90it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9134948253631592\n",
      "        eval_loss            2.688892364501953\n",
      "        hp_metric           0.9134948253631592\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caltech-101 Test Accuracy: 0.9135\n",
      "Testing DataLoader 0: 100%|██████████| 48/48 [00:05<00:00,  8.78it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8209150433540344\n",
      "        eval_loss           2.0995938777923584\n",
      "        hp_metric           0.8209150433540344\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 52. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caltech-256 Test Accuracy: 0.8209\n",
      "Loading pre-trained model: universal-resnet50-mcfp-multi-domain-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:01<00:00,  9.10it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9158016443252563\n",
      "        eval_loss           2.0957741737365723\n",
      "        hp_metric           0.9158016443252563\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caltech-101 Test Accuracy: 0.9158\n",
      "Testing DataLoader 0: 100%|██████████| 48/48 [00:05<00:00,  8.65it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8055555820465088\n",
      "        eval_loss            1.485878348350525\n",
      "        hp_metric           0.8055555820465088\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Caltech-256 Test Accuracy: 0.8056\n"
     ]
    }
   ],
   "source": [
    "# Create individual combined data modules for each domain\n",
    "# These maintain the (target, domain_id) tuple format expected by the universal models\n",
    "caltech101_combined_dm = CombinedDataModule(\n",
    "    dataset_modules=[caltech101_dm],\n",
    "    domain_ids=[0],  # Domain 0 for Caltech-101\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "caltech256_combined_dm = CombinedDataModule(\n",
    "    dataset_modules=[caltech256_dm],\n",
    "    domain_ids=[1],  # Domain 1 for Caltech-256\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "# Test each model on individual domains\n",
    "domain_results = {}\n",
    "for taxonomy_name, config in taxonomies_config.items():\n",
    "    # Load the trained model\n",
    "    print(f\"Loading pre-trained model: {config['model_name']}.ckpt\")\n",
    "    model = UniversalResNetModel.load_from_checkpoint(\n",
    "        f\"checkpoints/{config['model_name']}.ckpt\", taxonomy=config[\"taxonomy\"]\n",
    "    )\n",
    "\n",
    "    # Create trainer for testing\n",
    "    trainer = Trainer(\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "    )\n",
    "\n",
    "    domain_results[taxonomy_name] = {}\n",
    "\n",
    "    # Test on Caltech-101 (Domain 0)\n",
    "    caltech101_results = trainer.test(model, datamodule=caltech101_combined_dm)\n",
    "    domain_results[taxonomy_name][\"caltech101\"] = caltech101_results[0]\n",
    "    print(f\"Caltech-101 Test Accuracy: {caltech101_results[0]['eval_accuracy']:.4f}\")\n",
    "\n",
    "    # Test on Caltech-256 (Domain 1)\n",
    "    caltech256_results = trainer.test(model, datamodule=caltech256_combined_dm)\n",
    "    domain_results[taxonomy_name][\"caltech256\"] = caltech256_results[0]\n",
    "    print(f\"Caltech-256 Test Accuracy: {caltech256_results[0]['eval_accuracy']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
