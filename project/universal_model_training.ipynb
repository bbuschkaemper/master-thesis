{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249d7fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caltech-256 classes: 257\n",
      "Caltech-101 classes: 101\n",
      "CIFAR-100 classes: 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import Caltech256, Caltech101, CIFAR100\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "\n",
    "from library.taxonomy import Taxonomy\n",
    "from library.models import UniversalResNetModel\n",
    "from library.datasets import (\n",
    "    Caltech256DataModule,\n",
    "    Caltech101DataModule,\n",
    "    CIFAR100ScaledDataModule,\n",
    "    CombinedDataModule,\n",
    ")\n",
    "\n",
    "# Load dataset information\n",
    "caltech256_labels = Caltech256(root=\"datasets/caltech256\", download=False).categories\n",
    "caltech101_labels = Caltech101(root=\"datasets/caltech101\", download=False).categories\n",
    "cifar100_labels = CIFAR100(\n",
    "    root=\"datasets/cifar100\", download=False, train=False\n",
    ").classes\n",
    "\n",
    "print(f\"Caltech-256 classes: {len(caltech256_labels)}\")\n",
    "print(f\"Caltech-101 classes: {len(caltech101_labels)}\")\n",
    "print(f\"CIFAR-100 classes: {len(cifar100_labels)}\")\n",
    "\n",
    "# Reduce the precision of matrix multiplication to speed up training\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25714df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both taxonomies created from the real-world datasets\n",
    "hypothesis_taxonomy = Taxonomy.load(\"taxonomies/caltech256_caltech101_hypothesis.pkl\")\n",
    "mcfp_taxonomy = Taxonomy.load(\"taxonomies/caltech256_caltech101_mcfp.pkl\")\n",
    "\n",
    "# Load the three-domain taxonomies\n",
    "three_domain_hypothesis_taxonomy = Taxonomy.load(\n",
    "    \"taxonomies/three_domain_hypothesis.pkl\"\n",
    ")\n",
    "three_domain_mcfp_taxonomy = Taxonomy.load(\"taxonomies/three_domain_mcfp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a9cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Multi-Domain Training\n",
    "\n",
    "# Training configuration\n",
    "TRAIN = False  # Set to True to train model from scratch\n",
    "\n",
    "# Create individual dataset modules\n",
    "caltech101_dm = Caltech101DataModule(batch_size=32)\n",
    "caltech256_dm = Caltech256DataModule(batch_size=32)\n",
    "cifar100_dm = CIFAR100ScaledDataModule(batch_size=32)\n",
    "\n",
    "# Create combined data module with domain IDs\n",
    "# Domain 0: Caltech-101, Domain 1: Caltech-256\n",
    "dataset_module = CombinedDataModule(\n",
    "    dataset_modules=[caltech101_dm, caltech256_dm],\n",
    "    domain_ids=[0, 1],\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "# Create three-domain data module\n",
    "# Domain 0: Caltech-101, Domain 1: Caltech-256, Domain 2: CIFAR-100\n",
    "three_domain_dataset_module = CombinedDataModule(\n",
    "    dataset_modules=[caltech101_dm, caltech256_dm, cifar100_dm],\n",
    "    domain_ids=[0, 1, 2],\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "dataset_name = \"Caltech-101 + Caltech-256 (Multi-Domain)\"\n",
    "three_domain_dataset_name = \"Caltech-101 + Caltech-256 + CIFAR-100 (Three-Domain)\"\n",
    "\n",
    "# Configuration for both taxonomies\n",
    "taxonomies_config = {\n",
    "    \"hypothesis\": {\n",
    "        \"taxonomy\": hypothesis_taxonomy,\n",
    "        \"model_name\": \"universal-resnet50-hypothesis-multi-domain-min-val-loss\",\n",
    "        \"logger_name\": \"universal_hypothesis_multi_domain\",\n",
    "    },\n",
    "    \"mcfp\": {\n",
    "        \"taxonomy\": mcfp_taxonomy,\n",
    "        \"model_name\": \"universal-resnet50-mcfp-multi-domain-min-val-loss\",\n",
    "        \"logger_name\": \"universal_mcfp_multi_domain\",\n",
    "    },\n",
    "    \"three_domain_hypothesis\": {\n",
    "        \"taxonomy\": three_domain_hypothesis_taxonomy,\n",
    "        \"model_name\": \"universal-resnet50-three-domain-hypothesis-min-val-loss\",\n",
    "        \"logger_name\": \"universal_three_domain_hypothesis\",\n",
    "    },\n",
    "    \"three_domain_mcfp\": {\n",
    "        \"taxonomy\": three_domain_mcfp_taxonomy,\n",
    "        \"model_name\": \"universal-resnet50-three-domain-mcfp-min-val-loss\",\n",
    "        \"logger_name\": \"universal_three_domain_mcfp\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0c7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration (shared for both models)\n",
    "training_config = {\n",
    "    \"max_epochs\": 50,\n",
    "    \"optim\": \"adamw\",\n",
    "    \"optim_kwargs\": {\n",
    "        \"lr\": 0.00005,  # Reduced from 0.0001\n",
    "        \"weight_decay\": 0.001,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"eps\": 1e-8,\n",
    "    },\n",
    "    \"lr_scheduler\": \"cosine\",  # Changed from multistep\n",
    "    \"lr_scheduler_kwargs\": {\n",
    "        \"T_max\": 50,  # matches max_epochs\n",
    "        \"eta_min\": 1e-7,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb2e34cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: universal-resnet50-hypothesis-multi-domain-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   3%|▎         | 2/62 [00:01<00:35,  1.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 62/62 [00:08<00:00,  7.30it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8495034575462341\n",
      "        eval_loss           2.2322118282318115\n",
      "        hp_metric           0.8495034575462341\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 23. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: universal-resnet50-mcfp-multi-domain-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 62/62 [00:08<00:00,  7.35it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8265851736068726\n",
      "        eval_loss           1.6284024715423584\n",
      "        hp_metric           0.8265851736068726\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: universal-resnet50-three-domain-hypothesis-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 218/218 [00:27<00:00,  8.02it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy          0.789545476436615\n",
      "        eval_loss           2.1344213485717773\n",
      "        hp_metric            0.789545476436615\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 39. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/bjoern/dev/master-thesis/project/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | ResNet           | 26.4 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "26.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "26.4 M    Total params\n",
      "105.647   Total estimated model params size (MB)\n",
      "154       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1117/1117 [06:03<00:00,  3.07it/s, v_num=0]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 41. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1117/1117 [06:00<00:00,  3.10it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1117/1117 [06:00<00:00,  3.10it/s, v_num=0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/bjoern/dev/master-thesis/project/checkpoints/universal-resnet50-three-domain-mcfp-min-val-loss.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/bjoern/dev/master-thesis/project/checkpoints/universal-resnet50-three-domain-mcfp-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 218/218 [00:26<00:00,  8.18it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy          0.766999363899231\n",
      "        eval_loss           1.8517916202545166\n",
      "        hp_metric            0.766999363899231\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# Train models for both taxonomies\n",
    "results = {}\n",
    "\n",
    "for taxonomy_name, config in taxonomies_config.items():\n",
    "    # Select appropriate dataset module\n",
    "    if taxonomy_name in [\"three_domain_hypothesis\", \"three_domain_mcfp\"]:\n",
    "        current_dataset_module = three_domain_dataset_module\n",
    "    else:\n",
    "        current_dataset_module = dataset_module\n",
    "\n",
    "    # Create the Universal ResNet model for this taxonomy\n",
    "    model = UniversalResNetModel(\n",
    "        taxonomy=config[\"taxonomy\"],\n",
    "        architecture=\"resnet50\",\n",
    "        optim=training_config[\"optim\"],\n",
    "        optim_kwargs=training_config[\"optim_kwargs\"],\n",
    "        lr_scheduler=training_config[\"lr_scheduler\"],\n",
    "        lr_scheduler_kwargs=training_config[\"lr_scheduler_kwargs\"],\n",
    "    )\n",
    "\n",
    "    # Setup trainer\n",
    "    if TRAIN:\n",
    "        tb_logger = pl_loggers.TensorBoardLogger(\n",
    "            save_dir=\"logs\", name=config[\"logger_name\"]\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            max_epochs=training_config[\"max_epochs\"],\n",
    "            logger=tb_logger,\n",
    "            callbacks=[\n",
    "                ModelCheckpoint(\n",
    "                    dirpath=\"checkpoints\",\n",
    "                    monitor=\"val_accuracy\",\n",
    "                    mode=\"max\",\n",
    "                    save_top_k=1,\n",
    "                    filename=config[\"model_name\"],\n",
    "                    enable_version_counter=False,\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.fit(model, datamodule=current_dataset_module)\n",
    "\n",
    "        # Test the trained model\n",
    "        test_results = trainer.test(datamodule=current_dataset_module, ckpt_path=\"best\")\n",
    "\n",
    "    else:\n",
    "        trainer = Trainer(\n",
    "            logger=False,\n",
    "            enable_checkpointing=False,\n",
    "        )\n",
    "\n",
    "        # Load pre-trained model\n",
    "        print(f\"Loading pre-trained model: {config['model_name']}.ckpt\")\n",
    "        model = UniversalResNetModel.load_from_checkpoint(\n",
    "            f\"checkpoints/{config['model_name']}.ckpt\",\n",
    "            taxonomy=config[\n",
    "                \"taxonomy\"\n",
    "            ],  # Need to pass taxonomy since it's not serialized\n",
    "        )\n",
    "\n",
    "        # Test the loaded model\n",
    "        test_results = trainer.test(model, datamodule=current_dataset_module)\n",
    "\n",
    "    # Store results\n",
    "    results[taxonomy_name] = test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103b2c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: universal-resnet50-hypothesis-multi-domain-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:01<00:00,  8.29it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9192618131637573\n",
      "        eval_loss            2.693714141845703\n",
      "        hp_metric           0.9192618131637573\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 48/48 [00:05<00:00,  8.04it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8245097994804382\n",
      "        eval_loss            2.11551833152771\n",
      "        hp_metric           0.8245097994804382\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 52. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 62/62 [00:07<00:00,  8.09it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8467023372650146\n",
      "        eval_loss           2.2341432571411133\n",
      "        hp_metric           0.8467023372650146\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Loading pre-trained model: universal-resnet50-mcfp-multi-domain-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:02<00:00,  5.99it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9169549942016602\n",
      "        eval_loss            2.098475694656372\n",
      "        hp_metric           0.9169549942016602\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 48/48 [00:06<00:00,  7.90it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8009803891181946\n",
      "        eval_loss           1.4942468404769897\n",
      "        hp_metric           0.8009803891181946\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 62/62 [00:07<00:00,  8.31it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8276037573814392\n",
      "        eval_loss           1.6207640171051025\n",
      "        hp_metric           0.8276037573814392\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Loading pre-trained model: universal-resnet50-three-domain-hypothesis-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:01<00:00,  8.42it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9619377255439758\n",
      "        eval_loss           3.1650829315185547\n",
      "        hp_metric           0.9619377255439758\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 48/48 [00:06<00:00,  8.00it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8679738640785217\n",
      "        eval_loss            2.577457904815674\n",
      "        hp_metric           0.8679738640785217\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:18<00:00,  8.53it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7519999742507935\n",
      "        eval_loss           1.9138060808181763\n",
      "        hp_metric           0.7519999742507935\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 218/218 [00:26<00:00,  8.15it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7899044752120972\n",
      "        eval_loss            2.13614821434021\n",
      "        hp_metric           0.7899044752120972\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Loading pre-trained model: universal-resnet50-three-domain-mcfp-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:01<00:00,  8.25it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8350634574890137\n",
      "        eval_loss            2.671502113342285\n",
      "        hp_metric           0.8350634574890137\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 48/48 [00:06<00:00,  7.03it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7754902243614197\n",
      "        eval_loss            2.228153705596924\n",
      "        hp_metric           0.7754902243614197\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:18<00:00,  8.54it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7609999775886536\n",
      "        eval_loss           1.6658204793930054\n",
      "        hp_metric           0.7609999775886536\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 218/218 [00:26<00:00,  8.20it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7662813067436218\n",
      "        eval_loss           1.8523931503295898\n",
      "        hp_metric           0.7662813067436218\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# Create individual combined data modules for each domain\n",
    "# These maintain the (target, domain_id) tuple format expected by the universal models\n",
    "caltech101_combined_dm = CombinedDataModule(\n",
    "    dataset_modules=[caltech101_dm],\n",
    "    domain_ids=[0],  # Domain 0 for Caltech-101\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "caltech256_combined_dm = CombinedDataModule(\n",
    "    dataset_modules=[caltech256_dm],\n",
    "    domain_ids=[1],  # Domain 1 for Caltech-256\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "cifar100_combined_dm = CombinedDataModule(\n",
    "    dataset_modules=[cifar100_dm],\n",
    "    domain_ids=[2],  # Domain 2 for CIFAR-100\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "# Test each model on individual domains\n",
    "domain_results = {}\n",
    "for taxonomy_name, config in taxonomies_config.items():\n",
    "    # Load the trained model\n",
    "    print(f\"Loading pre-trained model: {config['model_name']}.ckpt\")\n",
    "    model = UniversalResNetModel.load_from_checkpoint(\n",
    "        f\"checkpoints/{config['model_name']}.ckpt\", taxonomy=config[\"taxonomy\"]\n",
    "    )\n",
    "\n",
    "    # Create trainer for testing\n",
    "    trainer = Trainer(\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "    )\n",
    "\n",
    "    domain_results[taxonomy_name] = {\n",
    "        \"name\": taxonomy_name,\n",
    "    }\n",
    "\n",
    "    # Test on Caltech-101 (Domain 0)\n",
    "    caltech101_results = trainer.test(model, datamodule=caltech101_combined_dm)\n",
    "    domain_results[taxonomy_name][\"caltech101\"] = caltech101_results[0][\"eval_accuracy\"]\n",
    "\n",
    "    # Test on Caltech-256 (Domain 1)\n",
    "    caltech256_results = trainer.test(model, datamodule=caltech256_combined_dm)\n",
    "    domain_results[taxonomy_name][\"caltech256\"] = caltech256_results[0][\"eval_accuracy\"]\n",
    "\n",
    "    # Test on CIFAR-100 (Domain 2) - only for three-domain model\n",
    "    if taxonomy_name in [\"three_domain_hypothesis\", \"three_domain_mcfp\"]:\n",
    "        cifar100_results = trainer.test(model, datamodule=cifar100_combined_dm)\n",
    "        domain_results[taxonomy_name][\"cifar100\"] = cifar100_results[0][\"eval_accuracy\"]\n",
    "\n",
    "        # Test on all three domains together\n",
    "        three_domain_results = trainer.test(\n",
    "            model, datamodule=three_domain_dataset_module\n",
    "        )\n",
    "        domain_results[taxonomy_name][\"unified\"] = three_domain_results[0][\n",
    "            \"eval_accuracy\"\n",
    "        ]\n",
    "    else:\n",
    "        # For two-domain models, CIFAR-100 accuracy is N/A\n",
    "        domain_results[taxonomy_name][\"cifar100\"] = None\n",
    "\n",
    "        # Test on original test (both)\n",
    "        original_results = trainer.test(model, datamodule=dataset_module)\n",
    "        domain_results[taxonomy_name][\"unified\"] = original_results[0][\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6810169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis taxonomy training duration: 2h 7m\n",
      "Mcfp taxonomy training duration: 2h 17m\n",
      "Three_domain_hypothesis taxonomy training duration: 4h 58m\n",
      "Three_domain_mcfp taxonomy training duration: 4h 59m\n",
      "                      name  caltech101  caltech256  cifar100   unified  \\\n",
      "0               hypothesis    0.919262    0.824510       NaN  0.846702   \n",
      "1                     mcfp    0.916955    0.800980       NaN  0.827604   \n",
      "2  three_domain_hypothesis    0.961938    0.867974     0.752  0.789904   \n",
      "3        three_domain_mcfp    0.835063    0.775490     0.761  0.766281   \n",
      "\n",
      "  training_time  \n",
      "0         2h 7m  \n",
      "1        2h 17m  \n",
      "2        4h 58m  \n",
      "3        4h 59m  \n"
     ]
    }
   ],
   "source": [
    "# Calculate training duration for each taxonomy\n",
    "from csv import DictReader\n",
    "import datetime\n",
    "\n",
    "\n",
    "def calculate_training_duration(file_prefix):\n",
    "    \"\"\"Calculate training duration from walltime in training CSV file\"\"\"\n",
    "    try:\n",
    "        with open(f\"training_results/{file_prefix}_train.csv\", \"r\") as f:\n",
    "            reader = DictReader(f)\n",
    "            rows = list(reader)\n",
    "\n",
    "            if not rows:\n",
    "                return \"N/A\"\n",
    "\n",
    "            # Get first and last walltime\n",
    "            start_time = float(rows[0][\"Wall time\"])\n",
    "            end_time = float(rows[-1][\"Wall time\"])\n",
    "\n",
    "            # Calculate duration in seconds\n",
    "            duration_seconds = end_time - start_time\n",
    "\n",
    "            # Convert to hours and minutes\n",
    "            hours = int(duration_seconds // 3600)\n",
    "            minutes = int((duration_seconds % 3600) // 60)\n",
    "\n",
    "            if hours > 0:\n",
    "                return f\"{hours}h {minutes}m\"\n",
    "            else:\n",
    "                return f\"{minutes}m\"\n",
    "    except FileNotFoundError:\n",
    "        return \"N/A\"\n",
    "\n",
    "\n",
    "# Calculate training durations for all taxonomies\n",
    "training_durations = {}\n",
    "for taxonomy_name, config in taxonomies_config.items():\n",
    "    duration = calculate_training_duration(config[\"logger_name\"])\n",
    "    training_durations[taxonomy_name] = duration\n",
    "    print(f\"{taxonomy_name.capitalize()} taxonomy training duration: {duration}\")\n",
    "\n",
    "# Add training duration to domain_results\n",
    "for taxonomy_name in domain_results:\n",
    "    domain_results[taxonomy_name][\"training_time\"] = training_durations[taxonomy_name]\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame.from_dict(domain_results, orient=\"index\")\n",
    "\n",
    "# Clear index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98b2bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LaTeX table from results\n",
    "# Transform the dataframe to have better column names for the table\n",
    "df_table = df.copy()\n",
    "\n",
    "# Map taxonomy names to display names for LaTeX export\n",
    "name_mapping = {\n",
    "    \"hypothesis\": \"Hypothesis (2)\",\n",
    "    \"mcfp\": \"MCFP (2)\",\n",
    "    \"three_domain_hypothesis\": \"Hypothesis (3)\",\n",
    "    \"three_domain_mcfp\": \"MCFP (3)\",\n",
    "}\n",
    "\n",
    "# Update the name column with display names\n",
    "df_table[\"name\"] = df_table[\"name\"].map(name_mapping)\n",
    "\n",
    "df_table.columns = [\n",
    "    \"Taxonomy\",\n",
    "    \"Caltech-101\",\n",
    "    \"Caltech-256\",\n",
    "    \"CIFAR-100\",\n",
    "    \"Avg\",\n",
    "    \"Training Time\",\n",
    "]\n",
    "\n",
    "# Reorder to move training time after taxonomy method\n",
    "df_table = df_table[\n",
    "    [\n",
    "        \"Taxonomy\",\n",
    "        \"Training Time\",\n",
    "        \"Caltech-101\",\n",
    "        \"Caltech-256\",\n",
    "        \"CIFAR-100\",\n",
    "        \"Avg\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Single domain baseline accuracies (as percentages)\n",
    "caltech101_baseline = 97.23  # 0.9723 * 100\n",
    "caltech256_baseline = 75.65  # 0.7565 * 100\n",
    "cifar100_baseline = 59.28  # 0.5928 * 100\n",
    "\n",
    "# Convert accuracy values to percentages and add delta values for domain columns\n",
    "df_table[\"Avg\"] = (df_table[\"Avg\"] * 100).round(2)\n",
    "\n",
    "# Convert columns to object type to avoid dtype warnings\n",
    "df_table[\"Caltech-101\"] = df_table[\"Caltech-101\"].astype(object)\n",
    "df_table[\"Caltech-256\"] = df_table[\"Caltech-256\"].astype(object)\n",
    "df_table[\"CIFAR-100\"] = df_table[\"CIFAR-100\"].astype(object)\n",
    "\n",
    "# Add delta values for domain columns\n",
    "for idx, row in df_table.iterrows():\n",
    "    # Caltech-101 column with delta\n",
    "    acc_101 = row[\"Caltech-101\"] * 100\n",
    "    delta_101 = acc_101 - caltech101_baseline\n",
    "    sign_101 = \"+\" if delta_101 >= 0 else \"\"\n",
    "    df_table.loc[idx, \"Caltech-101\"] = f\"{acc_101:.2f} ({sign_101}{delta_101:.2f})\"\n",
    "\n",
    "    # Caltech-256 column with delta\n",
    "    acc_256 = row[\"Caltech-256\"] * 100\n",
    "    delta_256 = acc_256 - caltech256_baseline\n",
    "    sign_256 = \"+\" if delta_256 >= 0 else \"\"\n",
    "    df_table.loc[idx, \"Caltech-256\"] = f\"{acc_256:.2f} ({sign_256}{delta_256:.2f})\"\n",
    "\n",
    "    # CIFAR-100 column with delta (only for three-domain model)\n",
    "    if pd.notna(row[\"CIFAR-100\"]) and row[\"CIFAR-100\"] is not None:\n",
    "        acc_100 = row[\"CIFAR-100\"] * 100\n",
    "        delta_100 = acc_100 - cifar100_baseline\n",
    "        sign_100 = \"+\" if delta_100 >= 0 else \"\"\n",
    "        df_table.loc[idx, \"CIFAR-100\"] = f\"{acc_100:.2f} ({sign_100}{delta_100:.2f})\"\n",
    "    else:\n",
    "        df_table.loc[idx, \"CIFAR-100\"] = \"N/A\"\n",
    "\n",
    "# Create LaTeX table\n",
    "latex_table = (\n",
    "    df_table.style.hide(axis=\"index\")\n",
    "    .format({\"Combined\": \"{:.2f}\"})  # Only format Combined column as numeric\n",
    "    .to_latex(\n",
    "        caption=\"Universal model evaluation results on multi-domain test datasets. Two-domain models were trained on Caltech-101 + Caltech-256, while the three-domain model was trained on all three datasets. Models were evaluated on individual domains as well as the combined test set. Domain accuracy values show performance compared to single-domain ResNet-50 baselines (Caltech-101: 97.23\\\\%, Caltech-256: 75.65\\\\%, CIFAR-100: 78.26\\\\%). All accuracy values are shown as percentages.\",\n",
    "        label=\"tab:universal_model_results\",\n",
    "        column_format=\"lcccccc\",\n",
    "        position=\"ht\",\n",
    "        position_float=\"centering\",\n",
    "        hrules=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save to file\n",
    "with open(\"../thesis/figures/universal_model_results.tex\", \"w\") as f:\n",
    "    f.write(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "170ab1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9098/35624902.py:95: UserWarning: FigureCanvasPgf is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "from csv import DictReader\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"pgf\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# LaTeX settings\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"EB Garamond\",\n",
    "        \"font.size\": 11,\n",
    "        \"pgf.texsystem\": \"lualatex\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create subplot with 4 plots, one for each taxonomy\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Configuration for all four taxonomies\n",
    "taxonomy_configs = [\n",
    "    {\n",
    "        \"name\": \"hypothesis\",\n",
    "        \"title\": \"Hypothesis Taxonomy (2 Domains)\",\n",
    "        \"file_prefix\": \"universal_hypothesis_multi_domain\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mcfp\",\n",
    "        \"title\": \"MCFP Taxonomy (2 Domains)\",\n",
    "        \"file_prefix\": \"universal_mcfp_multi_domain\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"three_domain\",\n",
    "        \"title\": \"Hypothesis Taxonomy (3 Domains)\",\n",
    "        \"file_prefix\": \"universal_three_domain_hypothesis\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"three_domain_mcfp\",\n",
    "        \"title\": \"MCFP Taxonomy (3 Domains)\",\n",
    "        \"file_prefix\": \"universal_three_domain_mcfp\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Plot training curves for each taxonomy\n",
    "for idx, config in enumerate(taxonomy_configs):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    try:\n",
    "        # Load training data\n",
    "        with open(f\"training_results/{config['file_prefix']}_train.csv\", \"r\") as f:\n",
    "            reader = DictReader(f)\n",
    "            steps_train = []\n",
    "            train = []\n",
    "            for row in reader:\n",
    "                steps_train.append(int(row[\"Step\"]))\n",
    "                train.append(float(row[\"Value\"]))\n",
    "\n",
    "        # Load validation data\n",
    "        with open(f\"training_results/{config['file_prefix']}_val.csv\", \"r\") as f:\n",
    "            reader = DictReader(f)\n",
    "            steps_val = []\n",
    "            val = []\n",
    "            for row in reader:\n",
    "                steps_val.append(int(row[\"Step\"]))\n",
    "                val.append(float(row[\"Value\"]))\n",
    "\n",
    "        # Plot training and validation curves\n",
    "        ax.plot(steps_train, train, label=\"Train\", color=\"blue\")\n",
    "        ax.plot(steps_val, val, label=\"Validation\", color=\"red\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # If training files don't exist, show a placeholder\n",
    "        ax.text(\n",
    "            0.5,\n",
    "            0.5,\n",
    "            f\"Training data\\nnot available\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            transform=ax.transAxes,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"),\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Steps\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(config[\"title\"])\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    \"../thesis/figures/universal_model_training_curves.pgf\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
