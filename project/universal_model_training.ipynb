{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249d7fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caltech-256 classes: 257\n",
      "Caltech-101 classes: 101\n",
      "CIFAR-100 classes: 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import Caltech256, Caltech101, CIFAR100\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "\n",
    "from library.taxonomy import Taxonomy\n",
    "from library.models import UniversalResNetModel\n",
    "from library.datasets import (\n",
    "    Caltech256DataModule,\n",
    "    Caltech101DataModule,\n",
    "    CIFAR100ScaledDataModule,\n",
    "    CIFAR100DataModule,\n",
    "    CombinedDataModule,\n",
    ")\n",
    "\n",
    "# Load dataset information\n",
    "caltech256_labels = Caltech256(root=\"datasets/caltech256\", download=False).categories\n",
    "caltech101_labels = Caltech101(root=\"datasets/caltech101\", download=False).categories\n",
    "cifar100_labels = CIFAR100(\n",
    "    root=\"datasets/cifar100\", download=False, train=False\n",
    ").classes\n",
    "\n",
    "print(f\"Caltech-256 classes: {len(caltech256_labels)}\")\n",
    "print(f\"Caltech-101 classes: {len(caltech101_labels)}\")\n",
    "print(f\"CIFAR-100 classes: {len(cifar100_labels)}\")\n",
    "\n",
    "# Reduce the precision of matrix multiplication to speed up training\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25714df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both taxonomies created from the real-world datasets\n",
    "hypothesis_taxonomy = Taxonomy.load(\"taxonomies/caltech256_caltech101_hypothesis.pkl\")\n",
    "mcfp_taxonomy = Taxonomy.load(\"taxonomies/caltech256_caltech101_mcfp.pkl\")\n",
    "\n",
    "# Load the three-domain taxonomies\n",
    "three_domain_hypothesis_taxonomy = Taxonomy.load(\n",
    "    \"taxonomies/three_domain_hypothesis.pkl\"\n",
    ")\n",
    "three_domain_mcfp_taxonomy = Taxonomy.load(\"taxonomies/three_domain_mcfp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a9cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Multi-Domain Training\n",
    "\n",
    "# Training configuration\n",
    "TRAIN = False  # Set to True to train model from scratch\n",
    "\n",
    "# Create individual dataset modules\n",
    "caltech101_dm = Caltech101DataModule(batch_size=32)\n",
    "caltech256_dm = Caltech256DataModule(batch_size=32)\n",
    "cifar100_dm = CIFAR100ScaledDataModule(batch_size=32)\n",
    "cifar100_original_dm = CIFAR100DataModule(batch_size=32)\n",
    "\n",
    "# Create combined data module with domain IDs\n",
    "# Domain 0: Caltech-101, Domain 1: Caltech-256\n",
    "dataset_module = CombinedDataModule(\n",
    "    dataset_modules=[caltech101_dm, caltech256_dm],\n",
    "    domain_ids=[0, 1],\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "# Create three-domain data module\n",
    "# Domain 0: Caltech-101, Domain 1: Caltech-256, Domain 2: CIFAR-100\n",
    "three_domain_dataset_module = CombinedDataModule(\n",
    "    dataset_modules=[caltech101_dm, caltech256_dm, cifar100_dm],\n",
    "    domain_ids=[0, 1, 2],\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "dataset_name = \"Caltech-101 + Caltech-256 (Multi-Domain)\"\n",
    "three_domain_dataset_name = \"Caltech-101 + Caltech-256 + CIFAR-100 (Three-Domain)\"\n",
    "\n",
    "# Configuration for both taxonomies\n",
    "taxonomies_config = {\n",
    "    \"hypothesis\": {\n",
    "        \"taxonomy\": hypothesis_taxonomy,\n",
    "        \"model_name\": \"universal-resnet50-hypothesis-multi-domain-min-val-loss\",\n",
    "        \"logger_name\": \"universal_hypothesis_multi_domain\",\n",
    "    },\n",
    "    \"mcfp\": {\n",
    "        \"taxonomy\": mcfp_taxonomy,\n",
    "        \"model_name\": \"universal-resnet50-mcfp-multi-domain-min-val-loss\",\n",
    "        \"logger_name\": \"universal_mcfp_multi_domain\",\n",
    "    },\n",
    "    \"three_domain_hypothesis\": {\n",
    "        \"taxonomy\": three_domain_hypothesis_taxonomy,\n",
    "        \"model_name\": \"universal-resnet50-three-domain-hypothesis-min-val-loss\",\n",
    "        \"logger_name\": \"universal_three_domain_hypothesis\",\n",
    "    },\n",
    "    \"three_domain_mcfp\": {\n",
    "        \"taxonomy\": three_domain_mcfp_taxonomy,\n",
    "        \"model_name\": \"universal-resnet50-three-domain-mcfp-min-val-loss\",\n",
    "        \"logger_name\": \"universal_three_domain_mcfp\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0c7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration (shared for both models)\n",
    "training_config = {\n",
    "    \"max_epochs\": 50,\n",
    "    \"optim\": \"adamw\",\n",
    "    \"optim_kwargs\": {\n",
    "        \"lr\": 0.00005,  # Reduced from 0.0001\n",
    "        \"weight_decay\": 0.001,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"eps\": 1e-8,\n",
    "    },\n",
    "    \"lr_scheduler\": \"cosine\",  # Changed from multistep\n",
    "    \"lr_scheduler_kwargs\": {\n",
    "        \"T_max\": 50,  # matches max_epochs\n",
    "        \"eta_min\": 1e-7,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb2e34cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: universal-resnet50-hypothesis-multi-domain-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   3%|▎         | 2/62 [00:01<00:46,  1.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 62/62 [00:09<00:00,  6.76it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8492487668991089\n",
      "        eval_loss           2.2416648864746094\n",
      "        hp_metric           0.8492487668991089\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8492487668991089\n",
      "        eval_loss           2.2416648864746094\n",
      "        hp_metric           0.8492487668991089\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 23. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: universal-resnet50-mcfp-multi-domain-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 62/62 [00:07<00:00,  7.88it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8250572681427002\n",
      "        eval_loss            1.626855492591858\n",
      "        hp_metric           0.8250572681427002\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8250572681427002\n",
      "        eval_loss            1.626855492591858\n",
      "        hp_metric           0.8250572681427002\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: universal-resnet50-three-domain-hypothesis-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 218/218 [00:27<00:00,  7.80it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7890428900718689\n",
      "        eval_loss           2.1360154151916504\n",
      "        hp_metric           0.7890428900718689\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7890428900718689\n",
      "        eval_loss           2.1360154151916504\n",
      "        hp_metric           0.7890428900718689\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 39. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: universal-resnet50-three-domain-mcfp-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 218/218 [00:27<00:00,  7.82it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7676455974578857\n",
      "        eval_loss           1.8525665998458862\n",
      "        hp_metric           0.7676455974578857\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7676455974578857\n",
      "        eval_loss           1.8525665998458862\n",
      "        hp_metric           0.7676455974578857\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# Train models for both taxonomies\n",
    "results = {}\n",
    "\n",
    "for taxonomy_name, config in taxonomies_config.items():\n",
    "    # Select appropriate dataset module\n",
    "    if taxonomy_name in [\"three_domain_hypothesis\", \"three_domain_mcfp\"]:\n",
    "        current_dataset_module = three_domain_dataset_module\n",
    "    else:\n",
    "        current_dataset_module = dataset_module\n",
    "\n",
    "    # Create the Universal ResNet model for this taxonomy\n",
    "    model = UniversalResNetModel(\n",
    "        taxonomy=config[\"taxonomy\"],\n",
    "        architecture=\"resnet50\",\n",
    "        optim=training_config[\"optim\"],\n",
    "        optim_kwargs=training_config[\"optim_kwargs\"],\n",
    "        lr_scheduler=training_config[\"lr_scheduler\"],\n",
    "        lr_scheduler_kwargs=training_config[\"lr_scheduler_kwargs\"],\n",
    "    )\n",
    "\n",
    "    # Setup trainer\n",
    "    if TRAIN:\n",
    "        tb_logger = pl_loggers.TensorBoardLogger(\n",
    "            save_dir=\"logs\", name=config[\"logger_name\"]\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            max_epochs=training_config[\"max_epochs\"],\n",
    "            logger=tb_logger,\n",
    "            callbacks=[\n",
    "                ModelCheckpoint(\n",
    "                    dirpath=\"checkpoints\",\n",
    "                    monitor=\"val_accuracy\",\n",
    "                    mode=\"max\",\n",
    "                    save_top_k=1,\n",
    "                    filename=config[\"model_name\"],\n",
    "                    enable_version_counter=False,\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.fit(model, datamodule=current_dataset_module)\n",
    "\n",
    "        # Test the trained model\n",
    "        test_results = trainer.test(datamodule=current_dataset_module, ckpt_path=\"best\")\n",
    "\n",
    "    else:\n",
    "        trainer = Trainer(\n",
    "            logger=False,\n",
    "            enable_checkpointing=False,\n",
    "        )\n",
    "\n",
    "        # Load pre-trained model\n",
    "        print(f\"Loading pre-trained model: {config['model_name']}.ckpt\")\n",
    "        model = UniversalResNetModel.load_from_checkpoint(\n",
    "            f\"checkpoints/{config['model_name']}.ckpt\",\n",
    "            taxonomy=config[\n",
    "                \"taxonomy\"\n",
    "            ],  # Need to pass taxonomy since it's not serialized\n",
    "        )\n",
    "\n",
    "        # Test the loaded model\n",
    "        test_results = trainer.test(model, datamodule=current_dataset_module)\n",
    "\n",
    "    # Store results\n",
    "    results[taxonomy_name] = test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103b2c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: universal-resnet50-hypothesis-multi-domain-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:01<00:00,  7.92it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9204152226448059\n",
      "        eval_loss           2.6933491230010986\n",
      "        hp_metric           0.9204152226448059\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9204152226448059\n",
      "        eval_loss           2.6933491230010986\n",
      "        hp_metric           0.9204152226448059\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 48/48 [00:06<00:00,  7.76it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8274509906768799\n",
      "        eval_loss           2.1112678050994873\n",
      "        hp_metric           0.8274509906768799\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8274509906768799\n",
      "        eval_loss           2.1112678050994873\n",
      "        hp_metric           0.8274509906768799\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 52. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 62/62 [00:08<00:00,  7.15it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8469569683074951\n",
      "        eval_loss            2.235304355621338\n",
      "        hp_metric           0.8469569683074951\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8469569683074951\n",
      "        eval_loss            2.235304355621338\n",
      "        hp_metric           0.8469569683074951\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Loading pre-trained model: universal-resnet50-mcfp-multi-domain-min-val-loss.ckpt\n",
      "Loading pre-trained model: universal-resnet50-mcfp-multi-domain-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:01<00:00,  8.25it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9088811874389648\n",
      "        eval_loss            2.092172622680664\n",
      "        hp_metric           0.9088811874389648\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:01<00:00,  8.25it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9088811874389648\n",
      "        eval_loss            2.092172622680664\n",
      "        hp_metric           0.9088811874389648\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 48/48 [00:06<00:00,  7.81it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8049019575119019\n",
      "        eval_loss           1.4988317489624023\n",
      "        hp_metric           0.8049019575119019\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8049019575119019\n",
      "        eval_loss           1.4988317489624023\n",
      "        hp_metric           0.8049019575119019\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 62/62 [00:07<00:00,  7.95it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8270944952964783\n",
      "        eval_loss           1.6252721548080444\n",
      "        hp_metric           0.8270944952964783\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8270944952964783\n",
      "        eval_loss           1.6252721548080444\n",
      "        hp_metric           0.8270944952964783\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Loading pre-trained model: universal-resnet50-three-domain-hypothesis-min-val-loss.ckpt\n",
      "Loading pre-trained model: universal-resnet50-three-domain-hypothesis-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:01<00:00,  8.18it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9573240876197815\n",
      "        eval_loss            3.164580821990967\n",
      "        hp_metric           0.9573240876197815\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:01<00:00,  8.18it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9573240876197815\n",
      "        eval_loss            3.164580821990967\n",
      "        hp_metric           0.9573240876197815\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 48/48 [00:07<00:00,  6.85it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8669934868812561\n",
      "        eval_loss            2.569204807281494\n",
      "        hp_metric           0.8669934868812561\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8669934868812561\n",
      "        eval_loss            2.569204807281494\n",
      "        hp_metric           0.8669934868812561\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:18<00:00,  8.34it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7519999742507935\n",
      "        eval_loss           1.9138060808181763\n",
      "        hp_metric           0.7519999742507935\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:18<00:00,  8.34it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7519999742507935\n",
      "        eval_loss           1.9138060808181763\n",
      "        hp_metric           0.7519999742507935\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 218/218 [00:27<00:00,  7.94it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7883248329162598\n",
      "        eval_loss            2.135984182357788\n",
      "        hp_metric           0.7883248329162598\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7883248329162598\n",
      "        eval_loss            2.135984182357788\n",
      "        hp_metric           0.7883248329162598\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Loading pre-trained model: universal-resnet50-three-domain-mcfp-min-val-loss.ckpt\n",
      "Loading pre-trained model: universal-resnet50-three-domain-mcfp-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:01<00:00,  7.66it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8304498195648193\n",
      "        eval_loss           2.6672072410583496\n",
      "        hp_metric           0.8304498195648193\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:01<00:00,  7.66it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.8304498195648193\n",
      "        eval_loss           2.6672072410583496\n",
      "        hp_metric           0.8304498195648193\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 48/48 [00:06<00:00,  7.79it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7676470875740051\n",
      "        eval_loss            2.230755567550659\n",
      "        hp_metric           0.7676470875740051\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7676470875740051\n",
      "        eval_loss            2.230755567550659\n",
      "        hp_metric           0.7676470875740051\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:19<00:00,  8.23it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7609999775886536\n",
      "        eval_loss           1.6658204793930054\n",
      "        hp_metric           0.7609999775886536\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7609999775886536\n",
      "        eval_loss           1.6658204793930054\n",
      "        hp_metric           0.7609999775886536\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 218/218 [00:26<00:00,  8.24it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7676455974578857\n",
      "        eval_loss           1.8520941734313965\n",
      "        hp_metric           0.7676455974578857\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.7676455974578857\n",
      "        eval_loss           1.8520941734313965\n",
      "        hp_metric           0.7676455974578857\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# Create individual combined data modules for each domain\n",
    "# These maintain the (target, domain_id) tuple format expected by the universal models\n",
    "caltech101_combined_dm = CombinedDataModule(\n",
    "    dataset_modules=[caltech101_dm],\n",
    "    domain_ids=[0],  # Domain 0 for Caltech-101\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "caltech256_combined_dm = CombinedDataModule(\n",
    "    dataset_modules=[caltech256_dm],\n",
    "    domain_ids=[1],  # Domain 1 for Caltech-256\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "cifar100_combined_dm = CombinedDataModule(\n",
    "    dataset_modules=[cifar100_dm],\n",
    "    domain_ids=[2],  # Domain 2 for CIFAR-100\n",
    "    batch_size=64,\n",
    "    num_workers=11,\n",
    ")\n",
    "\n",
    "# Test each model on individual domains\n",
    "domain_results = {}\n",
    "for taxonomy_name, config in taxonomies_config.items():\n",
    "    # Load the trained model\n",
    "    print(f\"Loading pre-trained model: {config['model_name']}.ckpt\")\n",
    "    model = UniversalResNetModel.load_from_checkpoint(\n",
    "        f\"checkpoints/{config['model_name']}.ckpt\", taxonomy=config[\"taxonomy\"]\n",
    "    )\n",
    "\n",
    "    # Create trainer for testing\n",
    "    trainer = Trainer(\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "    )\n",
    "\n",
    "    domain_results[taxonomy_name] = {\n",
    "        \"name\": taxonomy_name,\n",
    "    }\n",
    "\n",
    "    # Test on Caltech-101 (Domain 0)\n",
    "    caltech101_results = trainer.test(model, datamodule=caltech101_combined_dm)\n",
    "    domain_results[taxonomy_name][\"caltech101\"] = caltech101_results[0][\"eval_accuracy\"]\n",
    "\n",
    "    # Test on Caltech-256 (Domain 1)\n",
    "    caltech256_results = trainer.test(model, datamodule=caltech256_combined_dm)\n",
    "    domain_results[taxonomy_name][\"caltech256\"] = caltech256_results[0][\"eval_accuracy\"]\n",
    "\n",
    "    # Test on CIFAR-100 (Domain 2) - only for three-domain model\n",
    "    if taxonomy_name in [\"three_domain_hypothesis\", \"three_domain_mcfp\"]:\n",
    "        cifar100_results = trainer.test(model, datamodule=cifar100_combined_dm)\n",
    "        domain_results[taxonomy_name][\"cifar100\"] = cifar100_results[0][\"eval_accuracy\"]\n",
    "\n",
    "        # Test on all three domains together\n",
    "        three_domain_results = trainer.test(\n",
    "            model, datamodule=three_domain_dataset_module\n",
    "        )\n",
    "        domain_results[taxonomy_name][\"unified\"] = three_domain_results[0][\n",
    "            \"eval_accuracy\"\n",
    "        ]\n",
    "    else:\n",
    "        # For two-domain models, CIFAR-100 accuracy is N/A\n",
    "        domain_results[taxonomy_name][\"cifar100\"] = None\n",
    "\n",
    "        # Test on original test (both)\n",
    "        original_results = trainer.test(model, datamodule=dataset_module)\n",
    "        domain_results[taxonomy_name][\"unified\"] = original_results[0][\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6810169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis taxonomy training duration: 2h 7m\n",
      "Mcfp taxonomy training duration: 2h 17m\n",
      "Three_domain_hypothesis taxonomy training duration: 4h 58m\n",
      "Three_domain_mcfp taxonomy training duration: 4h 59m\n",
      "                      name  caltech101  caltech256  cifar100   unified  \\\n",
      "0               hypothesis    0.920415    0.827451       NaN  0.846957   \n",
      "1                     mcfp    0.908881    0.804902       NaN  0.827094   \n",
      "2  three_domain_hypothesis    0.957324    0.866993     0.752  0.788325   \n",
      "3        three_domain_mcfp    0.830450    0.767647     0.761  0.767646   \n",
      "\n",
      "  training_time  \n",
      "0         2h 7m  \n",
      "1        2h 17m  \n",
      "2        4h 58m  \n",
      "3        4h 59m  \n"
     ]
    }
   ],
   "source": [
    "# Calculate training duration for each taxonomy\n",
    "from csv import DictReader\n",
    "import datetime\n",
    "\n",
    "\n",
    "def calculate_training_duration(file_prefix):\n",
    "    \"\"\"Calculate training duration from walltime in training CSV file\"\"\"\n",
    "    try:\n",
    "        with open(f\"training_results/{file_prefix}_train.csv\", \"r\") as f:\n",
    "            reader = DictReader(f)\n",
    "            rows = list(reader)\n",
    "\n",
    "            if not rows:\n",
    "                return \"N/A\"\n",
    "\n",
    "            # Get first and last walltime\n",
    "            start_time = float(rows[0][\"Wall time\"])\n",
    "            end_time = float(rows[-1][\"Wall time\"])\n",
    "\n",
    "            # Calculate duration in seconds\n",
    "            duration_seconds = end_time - start_time\n",
    "\n",
    "            # Convert to hours and minutes\n",
    "            hours = int(duration_seconds // 3600)\n",
    "            minutes = int((duration_seconds % 3600) // 60)\n",
    "\n",
    "            if hours > 0:\n",
    "                return f\"{hours}h {minutes}m\"\n",
    "            else:\n",
    "                return f\"{minutes}m\"\n",
    "    except FileNotFoundError:\n",
    "        return \"N/A\"\n",
    "\n",
    "\n",
    "# Calculate training durations for all taxonomies\n",
    "training_durations = {}\n",
    "for taxonomy_name, config in taxonomies_config.items():\n",
    "    duration = calculate_training_duration(config[\"logger_name\"])\n",
    "    training_durations[taxonomy_name] = duration\n",
    "    print(f\"{taxonomy_name.capitalize()} taxonomy training duration: {duration}\")\n",
    "\n",
    "# Add training duration to domain_results\n",
    "for taxonomy_name in domain_results:\n",
    "    domain_results[taxonomy_name][\"training_time\"] = training_durations[taxonomy_name]\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame.from_dict(domain_results, orient=\"index\")\n",
    "\n",
    "# Clear index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54466759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline model: resnet50-caltech101-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/bjoern/miniconda3/envs/master-thesis/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 28/28 [00:03<00:00,  8.56it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9204152226448059\n",
      "        eval_loss           0.32788488268852234\n",
      "        hp_metric           0.9204152226448059\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Evaluating baseline model: resnet50-caltech256-min-val-loss.ckpt\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.9204152226448059\n",
      "        eval_loss           0.32788488268852234\n",
      "        hp_metric           0.9204152226448059\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Evaluating baseline model: resnet50-caltech256-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 96/96 [00:14<00:00,  6.83it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.6996731758117676\n",
      "        eval_loss           1.6147780418395996\n",
      "        hp_metric           0.6996731758117676\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Evaluating baseline model: resnet152-cifar100-min-val-loss.ckpt\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.6996731758117676\n",
      "        eval_loss           1.6147780418395996\n",
      "        hp_metric           0.6996731758117676\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Evaluating baseline model: resnet152-cifar100-min-val-loss.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 313/313 [00:10<00:00, 30.79it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.10859999805688858\n",
      "        eval_loss            4.112003803253174\n",
      "        hp_metric           0.10859999805688858\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval_accuracy         0.10859999805688858\n",
      "        eval_loss            4.112003803253174\n",
      "        hp_metric           0.10859999805688858\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Baseline Model Results:\n",
      "       Dataset Architecture Optimizer  Learning Rate Test Accuracy\n",
      "0  Caltech-101    ResNet-50       SGD          0.010         92.04\n",
      "1  Caltech-256    ResNet-50     AdamW          0.001         69.97\n",
      "2    CIFAR-100   ResNet-152     AdamW          0.001         10.86\n",
      "Baseline Model Results:\n",
      "       Dataset Architecture Optimizer  Learning Rate Test Accuracy\n",
      "0  Caltech-101    ResNet-50       SGD          0.010         92.04\n",
      "1  Caltech-256    ResNet-50     AdamW          0.001         69.97\n",
      "2    CIFAR-100   ResNet-152     AdamW          0.001         10.86\n"
     ]
    }
   ],
   "source": [
    "# Evaluate baseline models and create baseline table\n",
    "from library.models import ResNetModel\n",
    "\n",
    "# Baseline model configurations from the real-world taxonomy notebooks\n",
    "baseline_configs = {\n",
    "    \"Caltech-101\": {\n",
    "        \"checkpoint\": \"resnet50-caltech101-min-val-loss.ckpt\",\n",
    "        \"architecture\": \"ResNet-50\",\n",
    "        \"optimizer\": \"SGD\",\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"dataset_module\": caltech101_dm,  # Use individual dataset module\n",
    "    },\n",
    "    \"Caltech-256\": {\n",
    "        \"checkpoint\": \"resnet50-caltech256-min-val-loss.ckpt\",\n",
    "        \"architecture\": \"ResNet-50\",\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"dataset_module\": caltech256_dm,  # Use individual dataset module\n",
    "    },\n",
    "    \"CIFAR-100\": {\n",
    "        \"checkpoint\": \"resnet152-cifar100-min-val-loss.ckpt\",\n",
    "        \"architecture\": \"ResNet-152\",\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"dataset_module\": cifar100_original_dm,  # Use original CIFAR-100 dataset module\n",
    "    },\n",
    "}\n",
    "\n",
    "# Evaluate baseline models\n",
    "baseline_results = {}\n",
    "trainer = Trainer(logger=False, enable_checkpointing=False)\n",
    "\n",
    "for dataset_name, config in baseline_configs.items():\n",
    "    print(f\"Evaluating baseline model: {config['checkpoint']}\")\n",
    "\n",
    "    # Load baseline model\n",
    "    baseline_model = ResNetModel.load_from_checkpoint(\n",
    "        f\"checkpoints/{config['checkpoint']}\"\n",
    "    )\n",
    "\n",
    "    # Test on the dataset\n",
    "    test_results = trainer.test(baseline_model, datamodule=config[\"dataset_module\"])\n",
    "    accuracy = test_results[0][\"eval_accuracy\"] * 100  # Convert to percentage\n",
    "\n",
    "    baseline_results[dataset_name] = {\n",
    "        \"Dataset\": dataset_name,\n",
    "        \"Architecture\": config[\"architecture\"],\n",
    "        \"Optimizer\": config[\"optimizer\"],\n",
    "        \"Learning Rate\": config[\"learning_rate\"],\n",
    "        \"Test Accuracy\": f\"{accuracy:.2f}\",\n",
    "    }\n",
    "\n",
    "# Create baseline models dataframe\n",
    "baseline_df = pd.DataFrame.from_dict(baseline_results, orient=\"index\")\n",
    "baseline_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Baseline Model Results:\")\n",
    "print(baseline_df)\n",
    "\n",
    "# Create LaTeX table for baseline models\n",
    "baseline_latex_table = baseline_df.style.hide(axis=\"index\").to_latex(\n",
    "    caption=\"Baseline ResNet model performance on individual datasets. These single-domain models serve as reference points for evaluating the universal models.\",\n",
    "    label=\"tab:baseline_model_results\",\n",
    "    column_format=\"lcccc\",\n",
    "    position=\"ht\",\n",
    "    position_float=\"centering\",\n",
    "    hrules=True,\n",
    ")\n",
    "\n",
    "# Save baseline table to file\n",
    "with open(\"../thesis/figures/baseline_model_results.tex\", \"w\") as f:\n",
    "    f.write(baseline_latex_table)\n",
    "\n",
    "# Extract baseline accuracies for use in universal model table\n",
    "caltech101_baseline = float(baseline_results[\"Caltech-101\"][\"Test Accuracy\"])\n",
    "caltech256_baseline = float(baseline_results[\"Caltech-256\"][\"Test Accuracy\"])\n",
    "cifar100_baseline = float(baseline_results[\"CIFAR-100\"][\"Test Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b2bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LaTeX table from results\n",
    "# Transform the dataframe to have better column names for the table\n",
    "df_table = df.copy()\n",
    "\n",
    "# Map taxonomy names to display names for LaTeX export\n",
    "name_mapping = {\n",
    "    \"hypothesis\": \"Hypothesis (2 Domain)\",\n",
    "    \"mcfp\": \"MCFP (2 Domain)\",\n",
    "    \"three_domain_hypothesis\": \"Hypothesis (3 Domain)\",\n",
    "    \"three_domain_mcfp\": \"MCFP (3 Domain)\",\n",
    "}\n",
    "\n",
    "# Update the name column with display names\n",
    "df_table[\"name\"] = df_table[\"name\"].map(name_mapping)\n",
    "\n",
    "df_table.columns = [\n",
    "    \"Taxonomy\",\n",
    "    \"Caltech-101\",\n",
    "    \"Caltech-256\",\n",
    "    \"CIFAR-100\",\n",
    "    \"Avg\",\n",
    "    \"Training Time\",\n",
    "]\n",
    "\n",
    "# Reorder to move training time after taxonomy method\n",
    "df_table = df_table[\n",
    "    [\n",
    "        \"Taxonomy\",\n",
    "        \"Training Time\",\n",
    "        \"Caltech-101\",\n",
    "        \"Caltech-256\",\n",
    "        \"CIFAR-100\",\n",
    "        \"Avg\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Convert accuracy values to percentages and add delta values for domain columns\n",
    "df_table[\"Avg\"] = (df_table[\"Avg\"] * 100).round(2)\n",
    "\n",
    "# Store original numeric values for comparison\n",
    "orig_caltech101 = df_table[\"Caltech-101\"].values.copy()\n",
    "orig_caltech256 = df_table[\"Caltech-256\"].values.copy()\n",
    "orig_cifar100 = df_table[\"CIFAR-100\"].values.copy()\n",
    "orig_combined = df_table[\"Avg\"].values.copy()\n",
    "\n",
    "# Convert columns to object type to avoid dtype warnings\n",
    "df_table[\"Caltech-101\"] = df_table[\"Caltech-101\"].astype(object)\n",
    "df_table[\"Caltech-256\"] = df_table[\"Caltech-256\"].astype(object)\n",
    "df_table[\"CIFAR-100\"] = df_table[\"CIFAR-100\"].astype(object)\n",
    "df_table[\"Avg\"] = df_table[\"Avg\"].astype(object)\n",
    "\n",
    "# Find best values for each column (excluding N/A values for CIFAR-100)\n",
    "best_caltech101_idx = orig_caltech101.argmax()\n",
    "best_caltech256_idx = orig_caltech256.argmax()\n",
    "# For CIFAR-100, only consider rows that have valid values (three-domain models)\n",
    "valid_cifar100_mask = pd.notna(orig_cifar100) & (orig_cifar100 != None)\n",
    "if valid_cifar100_mask.any():\n",
    "    best_cifar100_idx = orig_cifar100[valid_cifar100_mask].argmax()\n",
    "    # Convert to actual dataframe index\n",
    "    best_cifar100_idx = df_table.index[valid_cifar100_mask][best_cifar100_idx]\n",
    "else:\n",
    "    best_cifar100_idx = -1  # No valid CIFAR-100 results\n",
    "best_combined_idx = orig_combined.argmax()\n",
    "\n",
    "# Add delta values for domain columns\n",
    "for idx, row in df_table.iterrows():\n",
    "    # Caltech-101 column with delta\n",
    "    acc_101 = row[\"Caltech-101\"] * 100\n",
    "    delta_101 = acc_101 - caltech101_baseline\n",
    "    sign_101 = \"+\" if delta_101 >= 0 else \"\"\n",
    "    result_str = f\"{acc_101:.2f} ({sign_101}{delta_101:.2f})\"\n",
    "    # Make best result bold\n",
    "    if idx == best_caltech101_idx:\n",
    "        result_str = f\"\\\\textbf{{{result_str}}}\"\n",
    "    df_table.loc[idx, \"Caltech-101\"] = result_str\n",
    "\n",
    "    # Caltech-256 column with delta\n",
    "    acc_256 = row[\"Caltech-256\"] * 100\n",
    "    delta_256 = acc_256 - caltech256_baseline\n",
    "    sign_256 = \"+\" if delta_256 >= 0 else \"\"\n",
    "    result_str = f\"{acc_256:.2f} ({sign_256}{delta_256:.2f})\"\n",
    "    # Make best result bold\n",
    "    if idx == best_caltech256_idx:\n",
    "        result_str = f\"\\\\textbf{{{result_str}}}\"\n",
    "    df_table.loc[idx, \"Caltech-256\"] = result_str\n",
    "\n",
    "    # CIFAR-100 column with delta (only for three-domain model)\n",
    "    if pd.notna(row[\"CIFAR-100\"]) and row[\"CIFAR-100\"] is not None:\n",
    "        acc_100 = row[\"CIFAR-100\"] * 100\n",
    "        delta_100 = acc_100 - cifar100_baseline\n",
    "        sign_100 = \"+\" if delta_100 >= 0 else \"\"\n",
    "        result_str = f\"{acc_100:.2f} ({sign_100}{delta_100:.2f})\"\n",
    "        # Make best result bold\n",
    "        if idx == best_cifar100_idx:\n",
    "            result_str = f\"\\\\textbf{{{result_str}}}\"\n",
    "        df_table.loc[idx, \"CIFAR-100\"] = result_str\n",
    "    else:\n",
    "        df_table.loc[idx, \"CIFAR-100\"] = \"N/A\"\n",
    "\n",
    "# Format Avg column with proper rounding (no bold highlighting)\n",
    "for idx, row in df_table.iterrows():\n",
    "    avg_value = orig_combined[idx]\n",
    "    df_table.loc[idx, \"Avg\"] = f\"{avg_value:.2f}\"\n",
    "\n",
    "# Create LaTeX table\n",
    "latex_table = df_table.style.hide(axis=\"index\").to_latex(\n",
    "    caption=\"Universal model evaluation results on multi-domain test datasets. Two-domain models were trained on Caltech-101 + Caltech-256, while three-domain models were trained on all three datasets. Models were evaluated on individual domains as well as the combined test set (no weighting was applied, the individual test sets were simply concatenated). Domain accuracy values show performance differences compared to single-domain baseline models (see Table~\\\\ref{tab:baseline_model_results}). Best results per column are shown in bold. All accuracy values are shown as percentages.\",\n",
    "    label=\"tab:universal_model_results\",\n",
    "    column_format=\"lcccccc\",\n",
    "    position=\"ht\",\n",
    "    position_float=\"centering\",\n",
    "    hrules=True,\n",
    ")\n",
    "\n",
    "# Save to file\n",
    "with open(\"../thesis/figures/universal_model_results.tex\", \"w\") as f:\n",
    "    f.write(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "170ab1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59794/35624902.py:95: UserWarning: FigureCanvasPgf is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "from csv import DictReader\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"pgf\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# LaTeX settings\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"EB Garamond\",\n",
    "        \"font.size\": 11,\n",
    "        \"pgf.texsystem\": \"lualatex\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create subplot with 4 plots, one for each taxonomy\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Configuration for all four taxonomies\n",
    "taxonomy_configs = [\n",
    "    {\n",
    "        \"name\": \"hypothesis\",\n",
    "        \"title\": \"Hypothesis Taxonomy (2 Domains)\",\n",
    "        \"file_prefix\": \"universal_hypothesis_multi_domain\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mcfp\",\n",
    "        \"title\": \"MCFP Taxonomy (2 Domains)\",\n",
    "        \"file_prefix\": \"universal_mcfp_multi_domain\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"three_domain\",\n",
    "        \"title\": \"Hypothesis Taxonomy (3 Domains)\",\n",
    "        \"file_prefix\": \"universal_three_domain_hypothesis\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"three_domain_mcfp\",\n",
    "        \"title\": \"MCFP Taxonomy (3 Domains)\",\n",
    "        \"file_prefix\": \"universal_three_domain_mcfp\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Plot training curves for each taxonomy\n",
    "for idx, config in enumerate(taxonomy_configs):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    try:\n",
    "        # Load training data\n",
    "        with open(f\"training_results/{config['file_prefix']}_train.csv\", \"r\") as f:\n",
    "            reader = DictReader(f)\n",
    "            steps_train = []\n",
    "            train = []\n",
    "            for row in reader:\n",
    "                steps_train.append(int(row[\"Step\"]))\n",
    "                train.append(float(row[\"Value\"]))\n",
    "\n",
    "        # Load validation data\n",
    "        with open(f\"training_results/{config['file_prefix']}_val.csv\", \"r\") as f:\n",
    "            reader = DictReader(f)\n",
    "            steps_val = []\n",
    "            val = []\n",
    "            for row in reader:\n",
    "                steps_val.append(int(row[\"Step\"]))\n",
    "                val.append(float(row[\"Value\"]))\n",
    "\n",
    "        # Plot training and validation curves\n",
    "        ax.plot(steps_train, train, label=\"Train\", color=\"blue\")\n",
    "        ax.plot(steps_val, val, label=\"Validation\", color=\"red\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # If training files don't exist, show a placeholder\n",
    "        ax.text(\n",
    "            0.5,\n",
    "            0.5,\n",
    "            f\"Training data\\nnot available\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            transform=ax.transAxes,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"),\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Steps\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(config[\"title\"])\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    \"../thesis/figures/universal_model_training_curves.pgf\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
