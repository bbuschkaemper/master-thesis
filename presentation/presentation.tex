\documentclass[aspectratio=169]{beamer}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgf}
\def\mathdefault#1{#1}
\usepackage{algorithm}
\usepackage{algpseudocode}

% Font configuration for PGF compatibility
\usepackage{ifxetex,ifluatex}
\newif\ifxetexorluatex
\ifxetex
  \xetexorluatextrue
\else
  \ifluatex
    \xetexorluatextrue
  \else
    \xetexorluatexfalse
  \fi
\fi

\ifxetexorluatex
  \usepackage{fontspec}
  \setmainfont{EB Garamond}
  \setmonofont[Scale=MatchLowercase]{Source Code Pro}
\else
  \usepackage[lf]{ebgaramond}
  \usepackage[oldstyle,scale=0.7]{sourcecodepro}
\fi

% Theme
\usetheme{Madrid}
\usecolortheme{default}

% Title page information
\title{Research and Implementation of Multi-Dataset Training for Image Classification with Discrepant Taxonomies}
\subtitle{Master Thesis Presentation}
\author{Björn Buschkämper}
\institute{Technical Faculty, Bielefeld University}
\date{\today}

\begin{document}

% Title slide
\begin{frame}
    \titlepage
\end{frame}

% Outline
\begin{frame}{Outline}
    \tableofcontents
\end{frame}

% Section 1: Introduction & Idea
\section{Introduction \& Idea}

\begin{frame}{The Challenge: Limited Scope of Traditional Models}
    \begin{itemize}
        \item Traditional image classification models are trained on specific datasets
        \item Each model recognizes only a predefined set of categories
        \item Multiple models needed for different domains = inefficient storage and deployment
    \end{itemize}

    \vspace{1em}

    \textbf{Current Approaches:}
    \begin{itemize}
        \item \textbf{Transfer Learning}: Adapt pre-trained models to new tasks
        \item \textbf{Multi-head Architecture}: Shared backbone + task-specific heads
    \end{itemize}

    \vspace{1em}

    \textcolor{red}{\textbf{Problem:}} Still requires separate models or heads for each domain
\end{frame}

\begin{frame}{Our Idea: Universal Model vs. Multi-Head}
    \begin{columns}[T]
        \begin{column}{0.48\textwidth}
            \textbf{Multi-Head Approach}
            \begin{itemize}
                \item Shared backbone
                \item Task-specific heads
                \item Automatic feature distillation
                \item Domain alignment challenges
            \end{itemize}

            \begin{center}
                \begin{tikzpicture}[scale=0.8]
                    % Backbone
                    \draw[thick, blue] (0,0) rectangle (2,1.5);
                    \node at (1,0.75) {\scriptsize Backbone};

                    % Heads (made wider)
                    \draw[thick, red] (0.1,1.5) rectangle (0.9,2.5);
                    \node at (0.5,2) {\tiny Head};
                    \draw[thick, red] (1.1,1.5) rectangle (1.9,2.5);
                    \node at (1.5,2) {\tiny Head};

                    % Labels
                    \node at (1,-0.3) {\tiny Input};
                    \node at (0.5,2.8) {\tiny A};
                    \node at (1.5,2.8) {\tiny B};
                \end{tikzpicture}
            \end{center}
        \end{column}

        \begin{column}{0.48\textwidth}
            \textbf{Universal Model Approach}
            \begin{itemize}
                \item Single shared model
                \item Universal output layer
                \item Predefined concept mapping
                \item Static domain conversion
            \end{itemize}

            \begin{center}
                \begin{tikzpicture}[scale=0.8]
                    % Model
                    \draw[thick, blue] (0,0) rectangle (2,1.5);
                    \node at (1,0.75) {\scriptsize Universal};
                    \node at (1,0.45) {\scriptsize Model};

                    % Universal output (made wider)
                    \draw[thick, green] (0.3,1.5) rectangle (1.7,2.5);
                    \node at (1,2) {\tiny Universal};
                    \node at (1,1.8) {\tiny Classes};

                    % Conversion
                    \draw[dashed] (1.7,2) -- (2.5,2.5);
                    \draw[dashed] (1.7,2) -- (2.5,1.5);
                    \node at (3,2.5) {\tiny Domain A};
                    \node at (3,1.5) {\tiny Domain B};

                    % Labels
                    \node at (1,-0.3) {\tiny Input};
                \end{tikzpicture}
            \end{center}
        \end{column}
    \end{columns}

    \vspace{1em}

    \textcolor{blue}{\textbf{Key Insight:}} Build explicit concept-to-domain mappings to train a single universal model
\end{frame}

\begin{frame}{Our Method in 3 Steps}
    \begin{center}
        \begin{tikzpicture}[node distance=3cm]
            % Step 1
            \draw[thick, blue] (0,0) rectangle (2.5,1.5);
            \node[align=center] at (1.25,0.75) {\textbf{Step 1:}\\Cross-Domain\\Prediction};

            % Step 2
            \draw[thick, orange] (3.5,0) rectangle (6,1.5);
            \node[align=center] at (4.75,0.75) {\textbf{Step 2:}\\Relationship\\Building};

            % Step 3
            \draw[thick, green] (7,0) rectangle (9.5,1.5);
            \node[align=center] at (8.25,0.75) {\textbf{Step 3:}\\Universal Model\\Training};

            % Arrows
            \draw[->, thick] (2.5,0.75) -- (3.5,0.75);
            \draw[->, thick] (6,0.75) -- (7,0.75);
        \end{tikzpicture}
    \end{center}

    \vspace{1em}

    \begin{enumerate}
        \item \textbf{Cross-Domain Prediction}: Train domain-specific models, run inference on other domains
        \item \textbf{Relationship Building}: Extract meaningful relationships from cross-domain predictions and create universal taxonomy
        \item \textbf{Universal Model Training}: Create and train a single model using universal taxonomy
    \end{enumerate}
\end{frame}

\begin{frame}{Changes to Method of Bevandic et al.}
    \begin{enumerate}
        \item \textbf{Weighted Relationships:} Instead of binary, unweighted relationships, we use weighted relationships to capture the strength of associations between classes.
        \item \textbf{Relationship Selection Methods:} We try multiple methods to select the most relevant relationships from noisy cross-domain predictions.
        \item \textbf{Synthetic Ground Truth:} We develop a synthetic ground truth generation method to be able to evaluate relationship selection methods in a controlled manner.
        \item \textbf{Discrete Probability Loss Function:} We use a loss function that allows training with probability distributions as targets, enabling the model to learn from the uncertainty in class relationships.
    \end{enumerate}
\end{frame}

% Section 2: Method Overview
\section{Method Overview}

\begin{frame}{Cross-Domain Prediction Process}
    \textbf{Goal}: Discover relationships between classes from different datasets

    \vspace{0.5em}

    \textbf{Process}:
    \begin{enumerate}
        \item Train domain-specific models
        \item Run each model on images from \emph{all other} domains, building prediction matrices $M_{ab}(i,j)$ = number of times class $c_i^a$ predicted as class $c_j^b$
        \item Create probability matrices $P_{ab}(i,j)$ = probability of classifying class $c_i^a$ as class $c_j^b$
    \end{enumerate}

    \vspace{0.5em}

    \begin{equation}
        P_{ab}(i, j) = \frac{M_{ab}(i, j)}{\sum_{k=1}^{|C_a|} M_{ab}(i, k)}
    \end{equation}

    \vspace{0.5em}

    \textbf{Example}: Caltech-256 class "car" predicated by CIFAR-100 model as "vehicle" ($80\%$), "bike" ($18\%$), "butterfly" ($2\%$)
\end{frame}

\begin{frame}{Challenge: Selecting Relevant Relationships}
    \textbf{Problems with raw probability matrices}:
    \begin{itemize}
        \item Noisy predictions from imperfect models
        \item Unknown number of true relationships
        \item Different datasets have different scales of similarity
    \end{itemize}

    \vspace{1em}

    \textbf{Solution}: Develop multiple relationship selection methods and evaluate them using a synthetic ground truth with custom metrics
\end{frame}

\begin{frame}{Relationship Selection Methods Explained}
    \begin{enumerate}
        \item \textbf{Most Common Foreign Prediction (MCFP) by Bevandic et al.}:
              \begin{equation}
                  \text{select\_relationships}(P_{ab}) = \{(i, j) \mid j = \text{argmax}_{j'} P_{ab}(i, j')\}
              \end{equation}

        \item \textbf{Naive Thresholding}:
              \begin{equation}
                  \text{select\_relationships}(P_{ab}) = \{(i, j) \mid P_{ab}(i, j) \geq t\}
              \end{equation}

        \item \textbf{Density Thresholding}: Select minimum relationships covering $p\%$ of probability mass

        \item \textbf{Relationship Hypothesis}: Assumes relationships based on shared concepts should have equal probabilities. For each class, find optimal $k$ relationships by minimizing:
              \begin{equation}
                  \sum_{j=1}^k \left| X_i(j) - \frac{1}{k} \right| + \sum_{j=k+1}^{|C_b|} X_i(j)
              \end{equation}
              where $X_i(j)$ are sorted probabilities in descending order.
    \end{enumerate}
\end{frame}

% Section 3: Method Evaluation
\section{Method Evaluation}

\begin{frame}{The Need for Controlled Ground Truth}
    \textbf{Problem}: No existing datasets with known inter-dataset, \textit{weighted} class relationships

    \vspace{1em}

    \textbf{Solution}: Merge classes from a single dataset into different variants with controlled relationships.

    \vspace{1em}

    \textbf{Example}:

    \begin{itemize}
        \item We have classes "car", "eye", "dog", "butterfly"
        \item Create Variant A: "\{car, eye\}", "\{butterfly\}"
        \item Create Variant B: "\{car, butterfly\}", "\{dog, eye\}"
        \item "A:\{car, eye\}" $\rightarrow$ "B:\{car, butterfly\}" ($50\%$)
        \item "B:\{car, butterfly\}" $\rightarrow$ "A:\{car, eye\}" ($50\%$)
        \item "A:\{butterfly\}" $\rightarrow$ "B:\{car, butterfly\}" ($100\%$)
        \item "B:\{car, butterfly\}" $\rightarrow$ "A:\{butterfly\}" ($50\%$)
    \end{itemize}
\end{frame}

\begin{frame}{Domain-Shifted Synthetic Datasets}
    \textbf{Problem}: Original synthetic variants too easy (same underlying images)

    \vspace{0.5em}

    \textbf{Solution}: Apply domain transformations to create realistic challenges

    \begin{columns}[T]
        \begin{column}{0.6\textwidth}
            \textbf{Transformations Applied}:
            \begin{itemize}
                \item \textbf{Variant A}: Noisy grayscale
                \item \textbf{Variant B}: Rotation + blur
                \item \textbf{Variant C}: Random erasing + color jitter + perspective shifts
            \end{itemize}

            \vspace{1em}

            \textbf{Results}:
            \begin{itemize}
                \item Model accuracy drops by ~10\%
                \item More realistic cross-domain predictions
                \item Better evaluation of relationship selection methods
            \end{itemize}
        \end{column}

        \begin{column}{0.35\textwidth}
            \begin{center}
                \includegraphics[width=\textwidth]{../thesis/figures/domain_shift_visualization.png}
            \end{center}
            \small{Example images from domain-shifted variants}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Evaluation Metrics for Relationship Selection}
    \textbf{How do we measure the quality of selected relationships?}

    \vspace{0.5em}

    \begin{enumerate}
        \item \textbf{Edge Difference Ratio (EDR)}: Measures difference in edge weights between predicted and ground truth graphs
              \begin{equation}
                  \text{EDR}(G_1, G_2) = \frac{\sum_{i,j} |A_1(i,j) - A_2(i,j)|}{\sum_{i,j} \max(A_1(i,j), A_2(i,j))}
              \end{equation}
              \textcolor{blue}{Range: [0,1], where 0 = identical graphs, 1 = no common edges}

        \item \textbf{Precision \& Recall}: Binary evaluation of relationship presence
              \begin{itemize}
                  \item Convert adjacency matrices to binary: $B(i,j) = 1$ if $A(i,j) > 0$
                  \item \textbf{Precision} = $\frac{TP}{TP + FP}$ (correctness of selected relationships)
                  \item \textbf{Recall} = $\frac{TP}{TP + FN}$ (coverage of true relationships)
                  \item \textbf{F1 Score} = Harmonic mean of precision and recall
              \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}{Relationship Selection Results: Domain-Shifted Evaluation}
    \textbf{Evaluation on domain-shifted synthetic datasets (more realistic)}

    \vspace{0.5em}

    \begin{table}[h]
        \centering
        \scriptsize
        \begin{tabular}{lccccc}
            \toprule
            \textbf{Method}         & \textbf{Parameter} & \textbf{EDR}   & \textbf{Precision} & \textbf{Recall} & \textbf{F1 Score} \\
            \midrule
            Relationship Hypothesis & 5                  & \textbf{0.759} & 0.390              & 0.543           & 0.444             \\
            Naive Thresholding      & 0.10               & 0.761          & 0.418              & 0.519           & \textbf{0.450}    \\
            Density Thresholding    & 0.60               & 0.766          & 0.349              & \textbf{0.582}  & 0.426             \\
            MCFP                    & N/A                & 0.842          & \textbf{0.490}     & 0.226           & 0.305             \\
            \bottomrule
        \end{tabular}
        \caption{Performance on domain-shifted synthetic datasets (Caltech-101, Caltech-256, CIFAR-100) with globally optimal parameters}
    \end{table}

    \vspace{0.5em}

    \textbf{Key Observations}:
    \begin{itemize}
        \item \textbf{Relationship Hypothesis} achieves best EDR 0.759
        \item \textbf{MCFP} maintains highest precision but lowest recall
        \item Maybe still not realistic enough, but suitable for getting method parameters
    \end{itemize}
\end{frame}


% Section 4: Universal Model
\section{Universal Model}

\begin{frame}{Universal Taxonomy Building Rules}
    \textbf{How do we convert relationship graphs into universal taxonomies?}

    \vspace{0.5em}

    \begin{enumerate}
        \item \textbf{Isolated Node Rule}: Classes with no relationships
              \begin{itemize}
                  \item Create new universal class for standalone domain classes
                  \item Ensures all classes are represented in universal taxonomy
              \end{itemize}

        \item \textbf{Bidirectional Relationship Rule}: Classes with mutual relationships (A $\leftrightarrow$ B)
              \begin{itemize}
                  \item Create single universal class C with relationships A $\rightarrow$ C, B $\rightarrow$ C
                  \item Indicates classes likely represent the same concept
              \end{itemize}

        \item \textbf{Transitive Cycle Rule}: Prevent invalid cycles (A $\rightarrow$ B $\rightarrow$ C where A, C same domain)
              \begin{itemize}
                  \item Remove relationship with lower probability
                  \item Classes within same domain should be disjoint
              \end{itemize}

        \item \textbf{Unilateral Relationship Rule}: Handle subset relationships (A $\rightarrow$ B)
              \begin{itemize}
                  \item Create universal class for shared concepts (A $\cup$ B)
                  \item Create universal class for unique concepts (B only)
              \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}{Taxonomy Visualization (Caltech-101 + Caltech-256)}
    \begin{center}
        \includegraphics[width=0.5\textwidth]{../thesis/figures/taxonomy.png}
    \end{center}
\end{frame}

\begin{frame}{Good Cluster}
    \begin{center}
        \includegraphics[width=0.35\textwidth]{../thesis/figures/wheel_concept.png}
    \end{center}
\end{frame}

\begin{frame}{Bad Cluster}
    \begin{center}
        \includegraphics[width=0.5\textwidth]{../thesis/figures/bad_taxonomy.png}
    \end{center}
\end{frame}

\begin{frame}{Building the Universal Model}

    \begin{itemize}
        \item Every universal class corresponds to one output neuron
        \item Each domain class maps to one or more universal classes
        \item Matrix $M_i$ maps domain $i$ classes to universal classes
    \end{itemize}

    \vspace{1em}

    \textbf{Target Generation}: Convert domain labels to universal class distributions
    \begin{equation}
        \mathbf{t} = \hat{M}_i[j, :] \quad \text{where } \hat{M}_i(j, u) = \frac{M_i(j, u)}{\sum_{u'} M_i(j, u')}
    \end{equation}

    \textbf{Loss Function}:
    \begin{equation}
        \mathcal{L} = -\sum_{u=1}^{|U|} \mathbf{t}(u) \log(\mathbf{p}(u))
    \end{equation}
\end{frame}

\begin{frame}{Multi-Domain Training Process}
    \textbf{Training Procedure}:
    \begin{enumerate}
        \item Concatenate domain datasets
        \item Each sample: $(\text{image}, (\text{domain\_id}, \text{label})) \rightarrow (\text{image}, \text{universal\_target})$
        \item Train universal model on unified dataset
    \end{enumerate}

    \vspace{1em}

    \textbf{Inference}:
    \begin{align}
        \mathbf{d}_i & = M_i^T \mathbf{p}            \\
        \hat{c}_i    & = \text{argmax}(\mathbf{d}_i)
    \end{align}

    where $\mathbf{p}$ are universal class predictions and $\hat{c}_i$ is the predicted class in domain $i$.
\end{frame}

% Section 5: Results
\section{Results}

\begin{frame}{Universal Model Performance}
    \textbf{Datasets}: Caltech-101, Caltech-256, CIFAR-100

    \begin{columns}[T]
        \begin{column}{0.48\textwidth}
            \textbf{Cal-101 + Cal-256 Results}
            \begin{table}[h]
                \centering
                \tiny
                \begin{tabular}{lcc}
                    \toprule
                    \textbf{Taxonomy} & \textbf{Cal-101}       & \textbf{Cal-256}        \\
                    \midrule
                    Hypothesis        & 91.81 (+0.00)          & 82.84 (+13.36)          \\
                    MCFP              & 91.23 (-0.58)          & 80.75 (+11.27)          \\
                    MCFP Binary       & 92.73 (+0.92)          & \textbf{89.71 (+20.23)} \\
                    Density           & 92.96 (+1.15)          & 81.54 (+12.06)          \\
                    Naive             & \textbf{93.19 (+1.38)} & 82.25 (+12.77)          \\
                    \bottomrule
                \end{tabular}
            \end{table}
        \end{column}

        \begin{column}{0.48\textwidth}
            \textbf{Cal-101 + Cal-256 + CIFAR Results}
            \begin{table}[h]
                \centering
                \tiny
                \begin{tabular}{lccc}
                    \toprule
                    \textbf{Taxonomy} & \textbf{Cal-101}       & \textbf{Cal-256}        & \textbf{CIFAR}          \\
                    \midrule
                    Hypothesis        & 68.74 (-23.07)         & 58.17 (-11.31)          & 69.03 (+8.55)           \\
                    MCFP              & 83.28 (-8.53)          & 76.50 (+7.02)           & 76.10 (+15.62)          \\
                    MCFP Binary       & 94.58 (+2.77)          & 85.13 (+15.65)          & 82.71 (+22.23)          \\
                    Density           & 95.39 (+3.58)          & 83.53 (+14.05)          & \textbf{83.14 (+22.66)} \\
                    Naive             & \textbf{95.50 (+3.69)} & \textbf{85.36 (+15.88)} & 72.56 (+12.08)          \\
                    \bottomrule
                \end{tabular}
            \end{table}
        \end{column}
    \end{columns}

    \vspace{0.5em}

    \textbf{Baselines}: Cal-101: 91.81\%, Cal-256: 69.48\%, CIFAR-100: 60.48\%

    \textbf{Key Findings}:
    \begin{itemize}
        \item Universal models \textcolor{blue}{\textbf{outperform}} single-domain baselines
        \item Different relationship selection methods excel on different datasets
        \item No single method consistently optimal across all scenarios
    \end{itemize}
\end{frame}

% Section 6: Conclusion
\section{Conclusion}

\begin{frame}{Key Contributions}
    \begin{enumerate}
        \item \textbf{Novel Weighted Graph Approach}: We have a \textit{weighted} relationship graph instead of binary edges

        \item \textbf{Comprehensive Relationship Selection Methods}: Four new proposed methods with detailed evaluation

        \item \textbf{Synthetic Ground Truth}: Controlled evaluation environment with domain-shifted variants

        \item \textbf{Reusable Taxonomy Framework}: Our code is adaptable to new taxonomy building rules,
              relationship selection methods, datasets and model architectures
    \end{enumerate}
\end{frame}

\begin{frame}{Main Findings}
    \textbf{Successful Aspects}:
    \begin{itemize}
        \item Universal models achieve better accuracy than single-domain models
        \item Our relationship graphs create meaningful, weighted inter-dataset class relationships
        \item Synthetic datasets provide a valuable, customizable evaluation environment
    \end{itemize}

    \vspace{1em}

    \textbf{Future Work \& Limitations}:
    \begin{itemize}
        \item No single relationship selection method works optimally for all cases
        \item Some bad clusters in universal taxonomy remain
        \item Tests were limited to 3-domain scenarios $\rightarrow$ need to scale to more datasets
        \item Try out for other vision tasks (e.g., object detection, segmentation)
    \end{itemize}
\end{frame}

\begin{frame}{Questions?}
    \begin{center}
        \textbf{\Large Thank you for your attention!}

        \vspace{1em}

        \textbf{Questions?}
    \end{center}
\end{frame}

\end{document}