%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Methodology}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
    \begin{minipage}{0.5\textwidth}
        \begin{small}
            In which we describe the approach to creating and evaluating synthetic taxonomies
            for comparing multiple image classification datasets.
        \end{small}
    \end{minipage}
    \vspace{0.5cm}
\end{center}

\section{Synthetic Taxonomy Generation}

\subsection{The Need for a Controlled Ground Truth}

To evaluate our taxonomy generation methods, we need a reliable ground truth with known relationships between datasets. This presents a challenge, as most existing image classification datasets lack clear inter-dataset relationships:

\begin{itemize}
    \item \textbf{ImageNet}~\cite{deng_imagenet_2009,russakovsky_imagenet_2015}
          uses WordNet's~\cite{fellbaum_wordnet_1998} hierarchical structure to organize classes.
          However, this strict hierarchy doesn't match our use case where we need to connect
          datasets with different class structures and partial overlaps.

    \item \textbf{Open Images}~\cite{kuznetsova_open_2020} contains approximately 9 million
          images with multiple labels per image generated by Google's Cloud Vision API\footnote{\url{https://cloud.google.com/vision}}.
          This multi-label approach makes it difficult to determine a single class for each image,
          which is required for our evaluation. Additionally, since most labels were automatically
          generated, it doesn't provide the verified ground truth we need.

    \item \textbf{iNaturalist}~\cite{horn_inaturalist_2018} offers a detailed taxonomy of
          plant and animal species, but its domain-specific nature makes it unsuitable
          for developing a general-purpose evaluation framework.
\end{itemize}

\subsection{Our Approach: Building Synthetic Datasets}

Instead of relying on existing taxonomies, we developed a method to generate synthetic datasets with controlled relationships. Our approach:

\begin{enumerate}
    \item Define a set of "atomic concepts" that serve as building blocks for classes
    \item Create multiple domains by sampling these concepts to form classes
    \item Calculate inter-domain relationships based on shared concepts
\end{enumerate}

This method allows us to precisely control the taxonomy structure while creating realistic relationships between domains. To generate images for these synthetic classes, we can leverage existing datasets by treating each original class as an atomic concept.

\subsection{Formal Definitions}

We define our synthetic taxonomy framework as follows:

\begin{equation}
    \begin{aligned}
        \mathcal{U}   & = \{1, 2, \ldots, n\} \quad \text{(Universe of atomic concepts)}                                                                                                                                           \\
        \mathcal{C}   & \subseteq \mathcal{U} \quad \text{(A class is a subset of concepts)}                                                                                                                                       \\
        \mathcal{D}_i & = \{\mathcal{C}_1^i, \mathcal{C}_2^i, \ldots, \mathcal{C}_k^i\} \quad \text{with } \forall j \neq k: \mathcal{C}_j^i \cap \mathcal{C}_k^i = \emptyset \quad \text{(A domain is a set of disjoint classes)} \\
        \mathcal{T}   & = \{\mathcal{D}_1, \mathcal{D}_2, \ldots, \mathcal{D}_m\} \quad \text{(A taxonomy is a set of domains)}
    \end{aligned}
\end{equation}

\subsection{Randomized Domain Generation}

To create realistic domains, we use controlled randomness:

\subsubsection{Parameter Sampling}

We sample the number of classes per domain and the number of concepts per class from truncated normal distributions to ensure realistic variation while maintaining control. Since normal distributions are unbounded, we use a truncated version:

\begin{equation*}
    f(x|\mu, \sigma, a, b) =
    \begin{cases}
        \frac{\phi\left(\frac{x-\mu}{\sigma}\right)}{\sigma\left[\Phi\left(\frac{b-\mu}{\sigma}\right) - \Phi\left(\frac{a-\mu}{\sigma}\right)\right]} & \text{if } a \leq x \leq b \\
        0                                                                                                                                              & \text{otherwise}
    \end{cases}
\end{equation*}

Where:
\begin{itemize}
    \item $\phi$ is the standard normal PDF
    \item $\Phi$ is the standard normal CDF
    \item $a$ and $b$ are lower and upper bounds
\end{itemize}

We implement this using SciPy's \texttt{truncnorm} module\footnote{\url{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.truncnorm.html}},
handling SciPy's standardization of bounds internally:

\begin{equation*}
    X \sim \text{TruncNorm}(\mu, \sigma^2, a, b)
\end{equation*}

\subsubsection{Domain Generation Algorithm}

To generate a domain $\mathcal{D}_i$, we follow these steps:

\begin{enumerate}
    \item \textbf{Sample domain size:} Determine how many concepts $l$ to use:
          \begin{equation*}
              l \sim \lfloor\text{TruncNorm}(\mu_{\text{classes}}, \sigma^2_{\text{classes}}, 1, n)\rceil
          \end{equation*}

    \item \textbf{Create concept pool:} Randomly select $l$ concepts from the universe:
          \begin{align*}
              P = \{a, b, c, \ldots\} \quad \text{where } a, b, c, \ldots \text{ are sampled without replacement from } \mathcal{U}
          \end{align*}

    \item \textbf{Initialize domain:} $\mathcal{D}_i = \{\}$

    \item \textbf{Generate classes:} While concepts remain in the pool ($P \neq \emptyset$):
          \begin{enumerate}
              \item Sample class size $s_j$:
                    \begin{equation*}
                        s_j \sim \lfloor\text{TruncNorm}(\mu_{\text{class\_size}}, \sigma^2_{\text{class\_size}}, 1, |P|)\rceil
                    \end{equation*}

              \item Form class $\mathcal{C}_j^i$ by selecting $s_j$ concepts randomly from $P$

              \item Remove selected concepts from $P$: $P = P \setminus \mathcal{C}_j^i$

              \item Add class to domain: $\mathcal{D}_i = \mathcal{D}_i \cup \{\mathcal{C}_j^i\}$
          \end{enumerate}
\end{enumerate}

This algorithm ensures that each concept is assigned to exactly one class within the domain, maintaining our disjointness constraint.

\subsection{Modeling Cross-Domain Relationships}

Once we've generated multiple domains, we need to model the relationships between them to create our ground truth.

\subsubsection{Simulating Neural Network Predictions}

Our taxonomy generation method assumes that neural network classifiers will predict related classes across domains with certain probabilities. To simulate this, we create "perfect" synthetic probabilities based on concept overlap.

\subsubsection{Relationship Calculation}

For any two domains $\mathcal{D}_A$ and $\mathcal{D}_B$, we calculate the probability of classifying an instance of class $\mathcal{C}_i^A$ as class $\mathcal{C}_j^B$ using:

\begin{equation}
    \begin{aligned}
        \text{NaiveProbability}(i, j) & = \frac{|\mathcal{C}_i^A \cap \mathcal{C}_j^B|}{|\mathcal{C}_i^A|}                          \\
        P_{i,j}                       & = \text{NaiveProbability}(i, j) + \frac{1 - \text{NaiveProbability}(i, j)}{|\mathcal{D}_B|}
    \end{aligned}
\end{equation}

Where:
\begin{itemize}
    \item $\text{NaiveProbability}(i, j)$ is the proportion of concepts in class $\mathcal{C}_i^A$ that also appear in class $\mathcal{C}_j^B$
    \item The second term distributes remaining probability mass evenly across all classes in domain $\mathcal{D}_B$, simulating the behavior of a neural network when encountering concepts it hasn't seen before
\end{itemize}

\subsubsection{A Concrete Example}

To illustrate this approach, consider two domains:
\begin{itemize}
    \item Domain A: $\mathcal{D}_A = \{\mathcal{C}_1^A=\{1,2\}, \mathcal{C}_2^A=\{3,4\}\}$
    \item Domain B: $\mathcal{D}_B = \{\mathcal{C}_1^B=\{1,2,4\}, \mathcal{C}_2^B=\{5,6\}\}$
\end{itemize}

For the relationship $\mathcal{C}_1^A \rightarrow \mathcal{C}_1^B$:
\begin{itemize}
    \item $\text{NaiveProbability}(1,1) = \frac{|\{1,2\} \cap \{1,2,4\}|}{|\{1,2\}|} = \frac{2}{2} = 1$
    \item $P_{1,1} = 1 + \frac{1-1}{2} = 1$
\end{itemize}

For the relationship $\mathcal{C}_2^A \rightarrow \mathcal{C}_1^B$:
\begin{itemize}
    \item $\text{NaiveProbability}(2,1) = \frac{|\{3,4\} \cap \{1,2,4\}|}{|\{3,4\}|} = \frac{1}{2} = 0.5$
    \item $P_{2,1} = 0.5 + \frac{1-0.5}{2} = 0.5 + 0.25 = 0.75$
\end{itemize}

This example shows how our framework captures partial relationships between classes and simulates how a neural network might handle concepts that don't perfectly match across domains.
