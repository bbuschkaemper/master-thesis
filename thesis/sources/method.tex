%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Methodology}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
    \begin{minipage}{0.5\textwidth}
        \begin{small}
            In which we describe our approaches to building a universal taxonomy
            for image classification.
        \end{small}
    \end{minipage}
    \vspace{0.5cm}
\end{center}

\section{Universal Taxonomy}

Our main goal is to create a universal taxonomy that connects multiple
image classification datasets.
This taxonomy maps every dataset class to a universal class,
which allows us to analyse the relationships and shared concepts between datasets.

In the end, our taxonomy will allow us to train models that can classify images
from multiple datasets at once, building a robust and flexible system
that can quickly adapt to new domains.

\subsection{Formal Definitions}

To formalise our algorithm for building a universal taxonomy,
we first need to define some terms:

\begin{itemize}
    \item \textbf{Dataset} $D$: A collection of images and labels
          written as $D = \{(x_1, c_1), (x_2, c_2), \ldots, (x_n, c_n)\}$,
          where $x_i$ is an image and $c_i$ is its label.
          Since we are dealing with multiple datasets, we number them
          as $D_i = \{(x_1^i, c_1^i), (x_2^i, c_2^i), \ldots, (x_n^i, c_n^i)\}$,
          where $D_i$ is the dataset $D$ with index $i$.
          In the same way, we denote the set of all classes in a dataset as $C_i = \{c_1^i, c_2^i, \ldots, c_k^i\}$.
          We denote the set of all datasets as $\mathbf{D} = \{D_1, D_2, \ldots, D_m\}$.
    \item \textbf{Model} $m$: A neural network trained on a dataset $D_I$
          which maps an image $x\in X$ to a class $c_i^I\in C_I$, denoted as $m_I: X \mapsto C_I$.
    \item \textbf{Domain}: Since both models and classes are dataset-specific,
          we define the term \textbf{domain} as the dataset $D_i$ and its classes $C_i$
          that we are working with.
    \item \textbf{Universal Classes}: Our universal taxonomy will contain a set of classes
          that are not specific to any dataset.
          We denote these classes as $C_U = \{c_1^U, c_2^U, \ldots, c_k^U\}$.
    \item \textbf{Graph}: We represent our taxonomy as a directed graph $G = (V, E)$,
          where $V$ is a set of vertices and $E$ is a set of edges.
          Each vertex $v_i$ represents a single class or universal class,
          which we define with $\text{class}: V \mapsto C$.
          Every edge $e_{ij}$ between two vertices $v_i$ and $v_j$ indicates
          a relationship $\text{class}(v_i) \rightarrow \text{class}(v_j)$.
    \item \textbf{Probability}: Every edge $e_{ij}$ has a probability associated with it,
          which indicates the likelihood of classifying an image from class $\text{class}(v_i)$
          as class $\text{class}(v_j)$.
          We denote this as a function $\text{probability}: E \mapsto [0, 1]$.
\end{itemize}

\subsection{Graph Construction}

Before building our universal taxonomy,
we need to construct our initial graph:

\begin{enumerate}
    \item \textbf{Foreign predictions:} For each dataset with its corresponding model,
          we run the model on all images from all other datasets.
          This gives us a set of predictions $P_{ab} = \{(x_i^a, c_j^b)\}$,
          where $x_i^a$ is an image from dataset $D_a$ and $c_j^b$ is the class
          predicted by model $m_b$ for that image.
    \item \textbf{Prediction probabilities:} We count the number of times each class $c_i^a$ was predicted
          as a foreign-domain class $c_j^b$.
          We denot this count in a matrix $M_{ab}\in \mathbb{N}_0^{|C_a| \times |C_b|}$,
          where $M_{ab}(i, j)$ is the number of times class $c_i^a$ was predicted
          as class $c_j^b$.
          We then divide each entry in the matrix by its row sum to get the
          probability of classifying an image from class $c_i^a$ as class $c_j^b$:
          \begin{equation*}
              P_{ab}(i, j) = \frac{M_{ab}(i, j)}{\sum_{k=1}^{|C_a|} M_{ab}(i, k)}
          \end{equation*}
          This gives us a matrix $P_{ab}\in [0, 1]^{|C_a| \times |C_b|}$,
          where $P_{ab}(i, j)$ is the probability of classifying an image from class $c_i^a$
          as class $c_j^b$.
    \item \textbf{Graph construction:} We now create a directed graph that represents the relationships between classes and datasets
          by iterating over every dataset $D_a$ with every dataset $D_b$ where $a \neq b$:
          \begin{enumerate}
              \item We collect the indices of the per-row maximum values in the matrix $P_{ab}$:
                    \begin{equation*}
                        I = \left\{\text{argmax}_{j\in\{1,\ldots,|C_b|\}} P_{ab}(i, j) \mid i\in\{1,\ldots,|C_a|\}\right\}
                    \end{equation*}
              \item For every $i\in \{1,\ldots,|C_a|\}$ where $P_{ab}(i, I_i) > 0$:
                    \begin{enumerate}
                        \item We create the vertices $v_k$ and $v_l$ for classes $c_i^a$ and $c_{I_i}^b$ respectively
                              if they do not already exist and add them to the graph
                              (otherwise we find the existing vertices for these classes as $v_k$ and $v_l$).
                        \item We create an edge $e_{kl}$ between the vertices $v_k$ and $v_l$ and add it to the graph.
                        \item We define $\text{probability}(e_{kl}) = P_{ab}(i, I_i)$.
                    \end{enumerate}
          \end{enumerate}
\end{enumerate}

\subsection{Taxonomy Generation}

% TODO

\section{Synthetic Taxonomy Generation}

\subsection{The Need for a Controlled Ground Truth}

To evaluate our taxonomy generation methods, we need a reliable ground truth with known relationships between datasets. This presents a challenge, as most existing image classification datasets lack clear inter-dataset relationships:

\begin{itemize}
    \item \textbf{ImageNet}~\cite{deng_imagenet_2009,russakovsky_imagenet_2015}
          uses WordNet's~\cite{fellbaum_wordnet_1998} hierarchical structure to organize classes.
          However, this strict hierarchy doesn't match our use case where we need to connect
          datasets with different class structures and partial overlaps.

    \item \textbf{Open Images}~\cite{kuznetsova_open_2020} contains approximately 9 million
          images with multiple labels per image generated by Google's Cloud Vision API\footnote{\url{https://cloud.google.com/vision}}.
          This multi-label approach makes it difficult to determine a single class for each image,
          which is required for our evaluation. Additionally, since most labels were automatically
          generated, it doesn't provide the verified ground truth we need.

    \item \textbf{iNaturalist}~\cite{horn_inaturalist_2018} offers a detailed taxonomy of
          plant and animal species, but its domain-specific nature makes it unsuitable
          for developing a general-purpose evaluation framework.
\end{itemize}

\subsection{Our Approach: Building Synthetic Datasets}

Instead of relying on existing taxonomies, we developed a method to generate synthetic datasets with controlled relationships. Our approach:

\begin{enumerate}
    \item Define a set of "atomic concepts" that serve as building blocks for classes
    \item Create multiple domains by sampling these concepts to form classes
    \item Calculate inter-domain relationships based on shared concepts
\end{enumerate}

This method allows us to precisely control the taxonomy structure while creating realistic relationships between domains. To generate images for these synthetic classes, we can leverage existing datasets by treating each original class as an atomic concept.

\subsection{Formal Definitions}

We define our synthetic taxonomy framework as follows:

\begin{equation}
    \begin{aligned}
        \mathcal{U}   & = \{1, 2, \ldots, n\} \quad \text{(Universe of atomic concepts)}                                                                                                                                           \\
        \mathcal{C}   & \subseteq \mathcal{U} \quad \text{(A class is a subset of concepts)}                                                                                                                                       \\
        \mathcal{D}_i & = \{\mathcal{C}_1^i, \mathcal{C}_2^i, \ldots, \mathcal{C}_k^i\} \quad \text{with } \forall j \neq k: \mathcal{C}_j^i \cap \mathcal{C}_k^i = \emptyset \quad \text{(A domain is a set of disjoint classes)} \\
        \mathcal{T}   & = \{\mathcal{D}_1, \mathcal{D}_2, \ldots, \mathcal{D}_m\} \quad \text{(A taxonomy is a set of domains)}
    \end{aligned}
\end{equation}

\subsection{Randomized Domain Generation}

To create realistic domains, we use controlled randomness:

\subsubsection{Parameter Sampling}

We sample the number of classes per domain and the number of concepts per class from truncated normal distributions to ensure realistic variation while maintaining control. Since normal distributions are unbounded, we use a truncated version:

\begin{equation*}
    f(x|\mu, \sigma, a, b) =
    \begin{cases}
        \frac{\phi\left(\frac{x-\mu}{\sigma}\right)}{\sigma\left[\Phi\left(\frac{b-\mu}{\sigma}\right) - \Phi\left(\frac{a-\mu}{\sigma}\right)\right]} & \text{if } a \leq x \leq b \\
        0                                                                                                                                              & \text{otherwise}
    \end{cases}
\end{equation*}

Where:
\begin{itemize}
    \item $\phi$ is the standard normal PDF
    \item $\Phi$ is the standard normal CDF
    \item $a$ and $b$ are lower and upper bounds
\end{itemize}

We implement this using SciPy's \texttt{truncnorm} module\footnote{\url{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.truncnorm.html}},
handling SciPy's standardization of bounds internally:

\begin{equation*}
    X \sim \text{TruncNorm}(\mu, \sigma^2, a, b)
\end{equation*}

\subsubsection{Domain Generation Algorithm}

To generate a domain $\mathcal{D}_i$, we follow these steps:

\begin{enumerate}
    \item \textbf{Sample domain size:} Determine how many concepts $l$ to use:
          \begin{equation*}
              l \sim \lfloor\text{TruncNorm}(\mu_{\text{classes}}, \sigma^2_{\text{classes}}, 1, n)\rceil
          \end{equation*}

    \item \textbf{Create concept pool:} Randomly select $l$ concepts from the universe:
          \begin{align*}
              P = \{a, b, c, \ldots\} \quad \text{where } a, b, c, \ldots \text{ are sampled without replacement from } \mathcal{U}
          \end{align*}

    \item \textbf{Initialize domain:} $\mathcal{D}_i = \{\}$

    \item \textbf{Generate classes:} While concepts remain in the pool ($P \neq \emptyset$):
          \begin{enumerate}
              \item Sample class size $s_j$:
                    \begin{equation*}
                        s_j \sim \lfloor\text{TruncNorm}(\mu_{\text{class\_size}}, \sigma^2_{\text{class\_size}}, 1, |P|)\rceil
                    \end{equation*}

              \item Form class $\mathcal{C}_j^i$ by selecting $s_j$ concepts randomly from $P$

              \item Remove selected concepts from $P$: $P = P \setminus \mathcal{C}_j^i$

              \item Add class to domain: $\mathcal{D}_i = \mathcal{D}_i \cup \{\mathcal{C}_j^i\}$
          \end{enumerate}
\end{enumerate}

This algorithm ensures that each concept is assigned to exactly one class within the domain, maintaining our disjointness constraint.

\subsection{Modeling Cross-Domain Relationships}

Once we've generated multiple domains, we need to model the relationships between them to create our ground truth.

\subsubsection{Simulating Neural Network Predictions}

Our taxonomy generation method assumes that neural network classifiers will predict related classes across domains with certain probabilities. To simulate this, we create "perfect" synthetic probabilities based on concept overlap.

\subsubsection{Relationship Calculation}

For any two domains $\mathcal{D}_A$ and $\mathcal{D}_B$, we calculate the probability of classifying an instance of class $\mathcal{C}_i^A$ as class $\mathcal{C}_j^B$ using:

\begin{equation}
    \begin{aligned}
        \text{NaiveProbability}(i, j) & = \frac{|\mathcal{C}_i^A \cap \mathcal{C}_j^B|}{|\mathcal{C}_i^A|}                          \\
        P_{i,j}                       & = \text{NaiveProbability}(i, j) + \frac{1 - \text{NaiveProbability}(i, j)}{|\mathcal{D}_B|}
    \end{aligned}
\end{equation}

Where:
\begin{itemize}
    \item $\text{NaiveProbability}(i, j)$ is the proportion of concepts in class $\mathcal{C}_i^A$ that also appear in class $\mathcal{C}_j^B$
    \item The second term distributes remaining probability mass evenly across all classes in domain $\mathcal{D}_B$, simulating the behavior of a neural network when encountering concepts it hasn't seen before
\end{itemize}

\subsubsection{A Concrete Example}

To illustrate this approach, consider two domains:
\begin{itemize}
    \item Domain A: $\mathcal{D}_A = \{\mathcal{C}_1^A=\{1,2\}, \mathcal{C}_2^A=\{3,4\}\}$
    \item Domain B: $\mathcal{D}_B = \{\mathcal{C}_1^B=\{1,2,4\}, \mathcal{C}_2^B=\{5,6\}\}$
\end{itemize}

For the relationship $\mathcal{C}_1^A \rightarrow \mathcal{C}_1^B$:
\begin{itemize}
    \item $\text{NaiveProbability}(1,1) = \frac{|\{1,2\} \cap \{1,2,4\}|}{|\{1,2\}|} = \frac{2}{2} = 1$
    \item $P_{1,1} = 1 + \frac{1-1}{2} = 1$
\end{itemize}

For the relationship $\mathcal{C}_2^A \rightarrow \mathcal{C}_1^B$:
\begin{itemize}
    \item $\text{NaiveProbability}(2,1) = \frac{|\{3,4\} \cap \{1,2,4\}|}{|\{3,4\}|} = \frac{1}{2} = 0.5$
    \item $P_{2,1} = 0.5 + \frac{1-0.5}{2} = 0.5 + 0.25 = 0.75$
\end{itemize}

This example shows how our framework captures partial relationships between classes and simulates how a neural network might handle concepts that don't perfectly match across domains.
