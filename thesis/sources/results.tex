\chapter{Results}

\section{Domain-Model Training}

\subsection{Datasets}

To start with our taxonomy generation,
we first need a set of datasets that we can use to train and evaluate our domain models:

\begin{itemize}
    \item \textbf{Caltech-101 and Caltech-256}~\cite{li_caltech_2022,griffin_caltech_2022}:
          The Caltech-101 dataset contains 101 general object categories with 40 to 800 images per category,
          while the Caltech-256 dataset extends this to 256 categories with at least 80 images per category.
          Both datasets have been widely used for image classification tasks\footnote{Over 500 open-access papers have cited the datasets, according to Papers with Code: \url{https://paperswithcode.com/dataset/caltech-101} and \url{https://paperswithcode.com/dataset/caltech-256}}.
          The images are roughly 300x200 pixels in size and contain annotated outlines
          for each object in the image, which we will not need for our purposes.
          The dataset has no predefined train/test split,
          so we will use a 80/10/10 split for training, validation, and testing.
    \item \textbf{CIFAR-100}~\cite{krizhevsky_learning_2009}:
          The CIFAR-100 datasets contains 100 classes grouped into 20 superclasses,
          with 600 images per class.
          Each image is 32x32 pixels in size, which is significantly smaller than the Caltech datasets.
          The dataset is one of the most popular datasets for image classification tasks\footnote{Over 5000 open-access papers have cited the dataset, according to Papers with Code: \url{https://paperswithcode.com/dataset/cifar-100}}.
          The dataset has a train/test split of 50000 training images and 10000 test images,
          which we will further split by dividing the training set into 80\% for training and 20\% for validation.
    \item \textbf{Synthetic Datasets}:
          To have a ground truth for our taxonomy generation,
          we will also create synthetic datasets based on the Caltech-101 and CIFAR-100 datasets.
          These datasets will be used to evaluate our cross-domain relationship graph generation
          methods (see Section~\ref{sec:graph_construction}).
          We will create synthetic datasets of varying sizes and complexity and evaluate
          how well our methods perform for different challenges.
\end{itemize}

\subsection{Training Domain Models}

\subsubsection{Model Architecture}

To now start our training of domain models,
we first need to define the architecture of our models.
The ResNet architecture\cite{he_deep_2015,he_identity_2016} is a popular choice for image classification tasks
and has been shown to perform well on a variety of datasets.
It also has the advantage of being pre-trained on the ImageNet dataset~\cite{deng_imagenet_2009,russakovsky_imagenet_2015},
which will save us the effort of training a model from scratch.
From the available ResNet architecture sizes,
we decide for the leaner ResNet-50 architecture to meet our resource constraints.

% TODO Tell how we modified the ResNet architecture to fit our needs.

% TODO: Describe how we trained the domain models for taxonomy generation
% TODO and what techniques we used. Lots of plots/figures etc. here.

\section{Taxonomy Generation}

% TODO: Display different taxonomies we generated and what is interesting about them.
% TODO: Describe what datasets we used and why we chose them.
% TODO: Compare and reference Bevandic taxonomy generation in contrast to our approach.

% TODO: Subsection to filtering methods and comparing them and their metrics.

\section{Universal Models}

% TODO
