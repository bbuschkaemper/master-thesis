\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Results}{15}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Domain-Model Training}{15}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Datasets}{15}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Training Domain Models}{16}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Model Architecture}{16}{subsubsection*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Training Procedure}{16}{subsubsection*.30}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Our ResNet-50 architecture with a funnel layer for classification. Blue blocks represent the input from the ResNet-50 architecture, red blocks represent the final output layer, and green blocks represent our new funnel layers.}}{17}{figure.caption.28}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:resnet_funnel}{{3.1}{17}{Our ResNet-50 architecture with a funnel layer for classification. Blue blocks represent the input from the ResNet-50 architecture, red blocks represent the final output layer, and green blocks represent our new funnel layers}{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Model Performance}{17}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Synthetic Variants}{17}{subsubsection*.33}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Overfitting on the CIFAR-100 dataset during training. The blue line represents the training accuracy, while the orange line represents the validation accuracy. The model overfits on the training data, resulting in a significant gap between the training and validation accuracy.}}{18}{figure.caption.31}\protected@file@percent }
\newlabel{fig:overfitting}{{3.2}{18}{Overfitting on the CIFAR-100 dataset during training. The blue line represents the training accuracy, while the orange line represents the validation accuracy. The model overfits on the training data, resulting in a significant gap between the training and validation accuracy}{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Model Accuracy}{19}{subsubsection*.36}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Taxonomy Generation}{19}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Relationship Selection Methods}{19}{subsection.3.2.1}\protected@file@percent }
\newlabel{sec:relationship_selection}{{3.2.1}{19}{Relationship Selection Methods}{subsection.3.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Synthetic Dataset Variants}{19}{subsubsection*.40}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Evaluation results on test sets. Models were checkpointed after every epoch and evaluated on the validation loss. The model with the lowest validation loss was selected for evaluation on the test set.}}{20}{table.caption.38}\protected@file@percent }
\newlabel{tab:evaluation_results}{{3.1}{20}{Evaluation results on test sets. Models were checkpointed after every epoch and evaluated on the validation loss. The model with the lowest validation loss was selected for evaluation on the test set}{table.caption.38}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Best EDR results for relationship discovery methods. For each dataset variant and method, the parameter values that yielded the lowest Edge Difference Ratio (EDR) are shown along with the corresponding F1-score.}}{21}{table.caption.44}\protected@file@percent }
\newlabel{tab:relationship_methods_best_edr}{{3.2}{21}{Best EDR results for relationship discovery methods. For each dataset variant and method, the parameter values that yielded the lowest Edge Difference Ratio (EDR) are shown along with the corresponding F1-score}{table.caption.44}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Critique on Synthetic Dataset Variants}{22}{subsubsection*.47}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Average performance metrics for relationship discovery methods with globally optimal parameters. Each method uses the parameter value that minimizes the average EDR across all dataset variants. Performance metrics are then averaged across all dataset variants using these optimal parameters.}}{23}{table.caption.45}\protected@file@percent }
\newlabel{tab:relationship_methods_global_optimal}{{3.3}{23}{Average performance metrics for relationship discovery methods with globally optimal parameters. Each method uses the parameter value that minimizes the average EDR across all dataset variants. Performance metrics are then averaged across all dataset variants using these optimal parameters}{table.caption.45}{}}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline WordNet Synsets}{23}{paragraph*.49}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\nonumberline SVHN-MNIST}{23}{paragraph*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Domain-Shift Synthetic Datasets}{23}{paragraph*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Universal Taxonomy Generation}{24}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Universal Models}{24}{section.3.3}\protected@file@percent }
\newlabel{fig:caltech256_2domain}{{3.3a}{25}{Caltech-256 2-domain variant 1\\ ($\mu _{\text {concepts}}=180$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=3$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.34}{}}
\newlabel{sub@fig:caltech256_2domain}{{a}{25}{Caltech-256 2-domain variant 1\\ ($\mu _{\text {concepts}}=180$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=3$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.34}{}}
\newlabel{fig:caltech256_2domain_variant}{{3.3b}{25}{Caltech-256 2-domain variant 2\\ ($\mu _{\text {concepts}}=200$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=2$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.34}{}}
\newlabel{sub@fig:caltech256_2domain_variant}{{b}{25}{Caltech-256 2-domain variant 2\\ ($\mu _{\text {concepts}}=200$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=2$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.34}{}}
\newlabel{fig:caltech256_3domain}{{3.3c}{25}{Caltech-256 3-domain variant\\ ($\mu _{\text {concepts}}=180$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=5$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.34}{}}
\newlabel{sub@fig:caltech256_3domain}{{c}{25}{Caltech-256 3-domain variant\\ ($\mu _{\text {concepts}}=180$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=5$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.34}{}}
\newlabel{fig:cifar100_2domain}{{3.3d}{25}{CIFAR-100 2-domain variant\\ ($\mu _{\text {concepts}}=50$, $\sigma ^2_{\text {concepts}}=5$,\\ $\mu _{\text {classes}}=3$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.34}{}}
\newlabel{sub@fig:cifar100_2domain}{{d}{25}{CIFAR-100 2-domain variant\\ ($\mu _{\text {concepts}}=50$, $\sigma ^2_{\text {concepts}}=5$,\\ $\mu _{\text {classes}}=3$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Synthetic dataset variants showing their relationship graphs before applying universal taxonomy algorithms. The number of concepts and classes per concept are sampled from truncated normal distributions with the parameters shown in each subfigure caption.}}{25}{figure.caption.34}\protected@file@percent }
\newlabel{fig:synthetic_variants}{{3.3}{25}{Synthetic dataset variants showing their relationship graphs before applying universal taxonomy algorithms. The number of concepts and classes per concept are sampled from truncated normal distributions with the parameters shown in each subfigure caption}{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Accuracy curves for all synthetic dataset variants. Each subplot shows training and validation accuracy over training steps for all domains in that variant. The models achieve final training accuracies of approximately 0.96-0.98 and validation accuracies of approximately 0.73-0.83.}}{26}{figure.caption.37}\protected@file@percent }
\newlabel{fig:all_training_runs}{{3.4}{26}{Accuracy curves for all synthetic dataset variants. Each subplot shows training and validation accuracy over training steps for all domains in that variant. The models achieve final training accuracies of approximately 0.96-0.98 and validation accuracies of approximately 0.73-0.83}{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Precision and recall plot of the \textbf  {naive thresholding method} for different thresholds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants.}}{27}{figure.caption.41}\protected@file@percent }
\newlabel{fig:naive_thresholding_precision_recall}{{3.5}{27}{Precision and recall plot of the \textbf {naive thresholding method} for different thresholds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants}{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Precision and recall plot of the \textbf  {density thresholding method} for different thresholds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants.}}{28}{figure.caption.42}\protected@file@percent }
\newlabel{fig:density_thresholding_precision_recall}{{3.6}{28}{Precision and recall plot of the \textbf {density thresholding method} for different thresholds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants}{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Precision and recall plot of the \textbf  {hypothesis method} for different upper bounds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants.}}{28}{figure.caption.43}\protected@file@percent }
\newlabel{fig:hypothesis_method_precision_recall}{{3.7}{28}{Precision and recall plot of the \textbf {hypothesis method} for different upper bounds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants}{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces This figure shows the complete Caltech101-Caltech256 universal taxonomy. While most classes build smaller clusters build smaller clusters of 2-3 classes, some large clusters can be observed.}}{29}{figure.caption.54}\protected@file@percent }
\newlabel{fig:taxonomy}{{3.8}{29}{This figure shows the complete Caltech101-Caltech256 universal taxonomy. While most classes build smaller clusters build smaller clusters of 2-3 classes, some large clusters can be observed}{figure.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces In the Caltech101-Caltech256 universal taxonomy, this cluster only contains vehicles. The universal classes created can be interpreted as sharing a common concept of \enquote {wheel}.}}{29}{figure.caption.55}\protected@file@percent }
\newlabel{fig:wheel_concept}{{3.9}{29}{In the Caltech101-Caltech256 universal taxonomy, this cluster only contains vehicles. The universal classes created can be interpreted as sharing a common concept of \enquote {wheel}}{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces This example in the Caltech101-Caltech256 universal taxonomy shows a wrong relationship cluster towards the Caltech101 class \enquote {binocular}. Many of the Caltech256 classes do not have a suitable representation in the Caltech101 dataset and then connect to the Caltech101 class \enquote {binocular} instead.}}{29}{figure.caption.56}\protected@file@percent }
\newlabel{fig:bad_taxonomy}{{3.10}{29}{This example in the Caltech101-Caltech256 universal taxonomy shows a wrong relationship cluster towards the Caltech101 class \enquote {binocular}. Many of the Caltech256 classes do not have a suitable representation in the Caltech101 dataset and then connect to the Caltech101 class \enquote {binocular} instead}{figure.caption.56}{}}
\@setckpt{sources/results}{
\setcounter{page}{30}
\setcounter{equation}{0}
\setcounter{enumi}{3}
\setcounter{enumii}{4}
\setcounter{enumiii}{3}
\setcounter{enumiv}{0}
\setcounter{footnote}{2}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{3}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{3}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{parentequation}{0}
\setcounter{su@anzahl}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{section@level}{1}
\setcounter{Item}{38}
\setcounter{Hfootnote}{4}
\setcounter{bookmark@seq@number}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{25}
\setcounter{maxnames}{99}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{2}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
}
