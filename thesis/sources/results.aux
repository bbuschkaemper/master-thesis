\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results \& Discussion}{21}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Domain Models}{21}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Datasets}{21}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Training}{22}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Model Architecture}{22}{subsubsection*.33}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Our ResNet-50 architecture with a funnel layer for classification. Blue blocks represent the input from the ResNet-50 architecture, red blocks represent the final output layer, and green blocks represent our new funnel layers.}}{22}{figure.caption.34}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:resnet_funnel}{{4.1}{22}{Our ResNet-50 architecture with a funnel layer for classification. Blue blocks represent the input from the ResNet-50 architecture, red blocks represent the final output layer, and green blocks represent our new funnel layers}{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Training Procedure}{22}{subsubsection*.36}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Overfitting on the CIFAR-100 dataset during training. The blue line represents the training accuracy, while the orange line represents the validation accuracy. The model overfits on the training data, resulting in a significant gap between the training and validation accuracy.}}{23}{figure.caption.37}\protected@file@percent }
\newlabel{fig:overfitting}{{4.2}{23}{Overfitting on the CIFAR-100 dataset during training. The blue line represents the training accuracy, while the orange line represents the validation accuracy. The model overfits on the training data, resulting in a significant gap between the training and validation accuracy}{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Model Performance}{24}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Synthetic Variants}{24}{subsubsection*.39}\protected@file@percent }
\newlabel{fig:caltech256_2domain}{{4.3a}{25}{Caltech-256 2-domain variant 1\\ ($\mu _{\text {concepts}}=180$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=3$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\newlabel{sub@fig:caltech256_2domain}{{a}{25}{Caltech-256 2-domain variant 1\\ ($\mu _{\text {concepts}}=180$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=3$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\newlabel{fig:caltech256_2domain_variant}{{4.3b}{25}{Caltech-256 2-domain variant 2\\ ($\mu _{\text {concepts}}=200$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=2$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\newlabel{sub@fig:caltech256_2domain_variant}{{b}{25}{Caltech-256 2-domain variant 2\\ ($\mu _{\text {concepts}}=200$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=2$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\newlabel{fig:caltech256_3domain}{{4.3c}{25}{Caltech-256 3-domain variant\\ ($\mu _{\text {concepts}}=180$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=5$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\newlabel{sub@fig:caltech256_3domain}{{c}{25}{Caltech-256 3-domain variant\\ ($\mu _{\text {concepts}}=180$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=5$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\newlabel{fig:cifar100_2domain}{{4.3d}{25}{CIFAR-100 2-domain variant\\ ($\mu _{\text {concepts}}=50$, $\sigma ^2_{\text {concepts}}=5$,\\ $\mu _{\text {classes}}=3$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\newlabel{sub@fig:cifar100_2domain}{{d}{25}{CIFAR-100 2-domain variant\\ ($\mu _{\text {concepts}}=50$, $\sigma ^2_{\text {concepts}}=5$,\\ $\mu _{\text {classes}}=3$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Synthetic dataset variants showing their relationship graphs before applying universal taxonomy algorithms. The number of concepts and classes per concept are sampled from truncated normal distributions with the parameters shown in each subfigure caption.}}{25}{figure.caption.40}\protected@file@percent }
\newlabel{fig:synthetic_variants}{{4.3}{25}{Synthetic dataset variants showing their relationship graphs before applying universal taxonomy algorithms. The number of concepts and classes per concept are sampled from truncated normal distributions with the parameters shown in each subfigure caption}{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Model Accuracy}{25}{subsubsection*.42}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Accuracy curves for all synthetic dataset variants. Each subplot shows training and validation accuracy over training steps for all domains in that variant. The models achieve final training accuracies of approximately 0.96-0.98 and validation accuracies of approximately 0.73-0.83.}}{26}{figure.caption.43}\protected@file@percent }
\newlabel{fig:all_training_runs}{{4.4}{26}{Accuracy curves for all synthetic dataset variants. Each subplot shows training and validation accuracy over training steps for all domains in that variant. The models achieve final training accuracies of approximately 0.96-0.98 and validation accuracies of approximately 0.73-0.83}{figure.caption.43}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Evaluation results on test sets. Models were checkpointed after every epoch and evaluated on the validation loss. The model with the lowest validation loss was selected for evaluation on the test set. Training time indicates the total duration from start to finish of model training.}}{26}{table.caption.44}\protected@file@percent }
\newlabel{tab:evaluation_results}{{4.1}{26}{Evaluation results on test sets. Models were checkpointed after every epoch and evaluated on the validation loss. The model with the lowest validation loss was selected for evaluation on the test set. Training time indicates the total duration from start to finish of model training}{table.caption.44}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Taxonomy Generation}{27}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Relationship Selection Methods}{27}{subsection.4.2.1}\protected@file@percent }
\newlabel{sec:relationship_selection}{{4.2.1}{27}{Relationship Selection Methods}{subsection.4.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Best EDR results for relationship discovery methods. For each dataset variant and method, the parameter values that yielded the lowest Edge Difference Ratio (EDR) are shown along with the corresponding F1-score.}}{28}{table.caption.45}\protected@file@percent }
\newlabel{tab:relationship_methods_best_edr}{{4.2}{28}{Best EDR results for relationship discovery methods. For each dataset variant and method, the parameter values that yielded the lowest Edge Difference Ratio (EDR) are shown along with the corresponding F1-score}{table.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Precision and recall plot of the \textbf  {naive thresholding method} for different thresholds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants.}}{29}{figure.caption.46}\protected@file@percent }
\newlabel{fig:naive_thresholding_precision_recall}{{4.5}{29}{Precision and recall plot of the \textbf {naive thresholding method} for different thresholds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants}{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Precision and recall plot of the \textbf  {density thresholding method} for different thresholds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants.}}{29}{figure.caption.47}\protected@file@percent }
\newlabel{fig:density_thresholding_precision_recall}{{4.6}{29}{Precision and recall plot of the \textbf {density thresholding method} for different thresholds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants}{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Precision and recall plot of the \textbf  {hypothesis method} for different upper bounds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants.}}{30}{figure.caption.48}\protected@file@percent }
\newlabel{fig:hypothesis_method_precision_recall}{{4.7}{30}{Precision and recall plot of the \textbf {hypothesis method} for different upper bounds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants}{figure.caption.48}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Average performance metrics for relationship discovery methods with globally optimal parameters. Each method uses the parameter value that minimizes the average EDR across all dataset variants. Performance metrics are then averaged across all dataset variants using these optimal parameters.}}{31}{table.caption.49}\protected@file@percent }
\newlabel{tab:relationship_methods_global_optimal}{{4.3}{31}{Average performance metrics for relationship discovery methods with globally optimal parameters. Each method uses the parameter value that minimizes the average EDR across all dataset variants. Performance metrics are then averaged across all dataset variants using these optimal parameters}{table.caption.49}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Critique on Synthetic Dataset Variants}{31}{subsubsection*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline WordNet Synsets}{32}{subsubsection*.53}\protected@file@percent }
\newlabel{sec:wordnet_synsets}{{4.2.1}{32}{WordNet Synsets}{subsubsection*.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces An example of a bad WordNet cluster in a relationship graph between Caltech256 and Caltech101. These false positives occur commonly and make WordNet unsuitable as a ground truth taxonomy.}}{33}{figure.caption.54}\protected@file@percent }
\newlabel{fig:wordnet}{{4.8}{33}{An example of a bad WordNet cluster in a relationship graph between Caltech256 and Caltech101. These false positives occur commonly and make WordNet unsuitable as a ground truth taxonomy}{figure.caption.54}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline SVHN-MNIST}{33}{subsubsection*.56}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces This figure shows the complete relationship graph between the SVHN and MNIST datasets. The relationships are unequivocal and straightforward, as the classes are identical across both datasets; however, they lack complexity.}}{34}{figure.caption.57}\protected@file@percent }
\newlabel{fig:svhn_mnist}{{4.9}{34}{This figure shows the complete relationship graph between the SVHN and MNIST datasets. The relationships are unequivocal and straightforward, as the classes are identical across both datasets; however, they lack complexity}{figure.caption.57}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Domain-Shift Synthetic Datasets}{34}{subsubsection*.59}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Example images from the domain-shifted synthetic variants. We apply different transformations to the images of the original synthetic dataset to create two new domains. The first domain (Domain A) is a noisy greyscale variant, while the second domain (Domain B) is a rotated, blurry version of the original images, and the third domain (Domain C) has random erasings, shifted perspectives, and color jitter.}}{35}{figure.caption.60}\protected@file@percent }
\newlabel{fig:domain_shift}{{4.10}{35}{Example images from the domain-shifted synthetic variants. We apply different transformations to the images of the original synthetic dataset to create two new domains. The first domain (Domain A) is a noisy greyscale variant, while the second domain (Domain B) is a rotated, blurry version of the original images, and the third domain (Domain C) has random erasings, shifted perspectives, and color jitter}{figure.caption.60}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Evaluation results on test sets for domain-shifted experiments. Models were trained with different domain shift transformations and checkpointed after every epoch. The model with the lowest validation loss was selected for evaluation on the test set. Training time indicates the total duration from start to finish of model training.}}{35}{table.caption.61}\protected@file@percent }
\newlabel{tab:evaluation_results_domain_shifted}{{4.4}{35}{Evaluation results on test sets for domain-shifted experiments. Models were trained with different domain shift transformations and checkpointed after every epoch. The model with the lowest validation loss was selected for evaluation on the test set. Training time indicates the total duration from start to finish of model training}{table.caption.61}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Average performance metrics for relationship discovery methods with globally optimal parameters on domain-shifted experiments. Each method uses the parameter value that minimizes the average EDR across all domain-shifted dataset variants. Performance metrics are then averaged across all dataset variants using these optimal parameters.}}{36}{table.caption.62}\protected@file@percent }
\newlabel{tab:relationship_methods_global_optimal_domain_shifted}{{4.5}{36}{Average performance metrics for relationship discovery methods with globally optimal parameters on domain-shifted experiments. Each method uses the parameter value that minimizes the average EDR across all domain-shifted dataset variants. Performance metrics are then averaged across all dataset variants using these optimal parameters}{table.caption.62}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Universal Taxonomy Generation}{37}{subsection.4.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces This figure shows the complete Caltech101-Caltech256 universal taxonomy. While most classes build smaller clusters build smaller clusters of 2-3 classes, some large clusters can be observed.}}{37}{figure.caption.63}\protected@file@percent }
\newlabel{fig:taxonomy}{{4.11}{37}{This figure shows the complete Caltech101-Caltech256 universal taxonomy. While most classes build smaller clusters build smaller clusters of 2-3 classes, some large clusters can be observed}{figure.caption.63}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces In the Caltech101-Caltech256 universal taxonomy, this cluster only contains vehicles. The universal classes created can be interpreted as sharing a common concept of \enquote {wheel}.}}{38}{figure.caption.64}\protected@file@percent }
\newlabel{fig:wheel_concept}{{4.12}{38}{In the Caltech101-Caltech256 universal taxonomy, this cluster only contains vehicles. The universal classes created can be interpreted as sharing a common concept of \enquote {wheel}}{figure.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces This example in the Caltech101-Caltech256 universal taxonomy shows a wrong relationship cluster towards the Caltech101 class \enquote {binocular}. Many of the Caltech256 classes do not have a suitable representation in the Caltech101 dataset and then connect to the Caltech101 class \enquote {binocular} instead.}}{38}{figure.caption.65}\protected@file@percent }
\newlabel{fig:bad_taxonomy}{{4.13}{38}{This example in the Caltech101-Caltech256 universal taxonomy shows a wrong relationship cluster towards the Caltech101 class \enquote {binocular}. Many of the Caltech256 classes do not have a suitable representation in the Caltech101 dataset and then connect to the Caltech101 class \enquote {binocular} instead}{figure.caption.65}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Universal Models}{39}{section.4.3}\protected@file@percent }
\newlabel{sec:universal_models}{{4.3}{39}{Universal Models}{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Training}{39}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Modifications to Baseline Architecture}{39}{subsubsection*.67}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Multi-Domain Training Procedure}{40}{subsubsection*.69}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Performance}{40}{subsection.4.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Training curves for universal models using both hypothesis and MCFP taxonomies on the multi-domain Caltech-101 + Caltech-256 dataset. Both models show stable convergence with the hypothesis taxonomy achieving slightly better performance.}}{41}{figure.caption.70}\protected@file@percent }
\newlabel{fig:universal_model_training_curves}{{4.14}{41}{Training curves for universal models using both hypothesis and MCFP taxonomies on the multi-domain Caltech-101 + Caltech-256 dataset. Both models show stable convergence with the hypothesis taxonomy achieving slightly better performance}{figure.caption.70}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Baseline ResNet model performance on individual datasets. These single-domain models serve as reference points for evaluating the universal models. Every baseline model was trained for 50 epochs.}}{41}{table.caption.71}\protected@file@percent }
\newlabel{tab:baseline_model_results}{{4.6}{41}{Baseline ResNet model performance on individual datasets. These single-domain models serve as reference points for evaluating the universal models. Every baseline model was trained for 50 epochs}{table.caption.71}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Universal model evaluation results for two-domain models trained on Caltech-101 + Caltech-256. Models were evaluated on the test sets of the individual domains. Domain accuracy values show performance differences compared to single-domain baseline models (see Table~\ref {tab:baseline_model_results}). Best results per column are shown in bold. All accuracy values are shown as percentages. Density Threshold models use parameter 0.6, Naive Threshold models use parameter 0.1.}}{42}{table.caption.72}\protected@file@percent }
\newlabel{tab:universal_model_results_2domain}{{4.7}{42}{Universal model evaluation results for two-domain models trained on Caltech-101 + Caltech-256. Models were evaluated on the test sets of the individual domains. Domain accuracy values show performance differences compared to single-domain baseline models (see Table~\ref {tab:baseline_model_results}). Best results per column are shown in bold. All accuracy values are shown as percentages. Density Threshold models use parameter 0.6, Naive Threshold models use parameter 0.1}{table.caption.72}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Universal model evaluation results for three-domain models trained on Caltech-101 + Caltech-256 + CIFAR-100. Models were evaluated on the test sets of the individual domains. Domain accuracy values show performance differences compared to single-domain baseline models (see Table~\ref {tab:baseline_model_results}). Best results per column are shown in bold. All accuracy values are shown as percentages. Density Threshold models use parameter 0.6, Naive Threshold models use parameter 0.1.}}{42}{table.caption.73}\protected@file@percent }
\newlabel{tab:universal_model_results_3domain}{{4.8}{42}{Universal model evaluation results for three-domain models trained on Caltech-101 + Caltech-256 + CIFAR-100. Models were evaluated on the test sets of the individual domains. Domain accuracy values show performance differences compared to single-domain baseline models (see Table~\ref {tab:baseline_model_results}). Best results per column are shown in bold. All accuracy values are shown as percentages. Density Threshold models use parameter 0.6, Naive Threshold models use parameter 0.1}{table.caption.73}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Feature Visualization}{43}{subsection.4.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.15}{\ignorespaces t-SNE visualization of the final output layer representations for the universal models on the Caltech-101 + Caltech-256 taxonomies. Classes are represented through colours, marker shapes indicate the dataset. Circles represent the Caltech-101 dataset, stars represent the Caltech-256 dataset.}}{43}{figure.caption.74}\protected@file@percent }
\newlabel{fig:universal_features_2domain_tsne}{{4.15}{43}{t-SNE visualization of the final output layer representations for the universal models on the Caltech-101 + Caltech-256 taxonomies. Classes are represented through colours, marker shapes indicate the dataset. Circles represent the Caltech-101 dataset, stars represent the Caltech-256 dataset}{figure.caption.74}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.16}{\ignorespaces t-SNE visualization of the final output layer representations for the universal models on the Caltech-101 + Caltech-256 + CIFAR-100 taxonomies. Classes are represented through colours, marker shapes indicate the dataset. Circles represent the Caltech-101 dataset, stars represent the Caltech-256 dataset, and triangles represent the CIFAR-100 dataset.}}{44}{figure.caption.75}\protected@file@percent }
\newlabel{fig:universal_features_3domain_tsne}{{4.16}{44}{t-SNE visualization of the final output layer representations for the universal models on the Caltech-101 + Caltech-256 + CIFAR-100 taxonomies. Classes are represented through colours, marker shapes indicate the dataset. Circles represent the Caltech-101 dataset, stars represent the Caltech-256 dataset, and triangles represent the CIFAR-100 dataset}{figure.caption.75}{}}
\@setckpt{sources/results}{
\setcounter{page}{45}
\setcounter{equation}{0}
\setcounter{enumi}{3}
\setcounter{enumii}{4}
\setcounter{enumiii}{3}
\setcounter{enumiv}{0}
\setcounter{footnote}{2}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{3}
\setcounter{subsection}{3}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{16}
\setcounter{table}{8}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{parentequation}{0}
\setcounter{su@anzahl}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{section@level}{2}
\setcounter{Item}{38}
\setcounter{Hfootnote}{4}
\setcounter{bookmark@seq@number}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{53}
\setcounter{maxnames}{99}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{2}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{float@type}{4}
}
