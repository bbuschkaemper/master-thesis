\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results}{21}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Domain Models}{21}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Datasets}{21}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Training}{22}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Model Architecture}{22}{subsubsection*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Training Procedure}{22}{subsubsection*.36}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Our ResNet-50 architecture with a funnel layer for classification. Blue blocks represent the input from the ResNet-50 architecture, red blocks represent the final output layer, and green blocks represent our new funnel layers.}}{23}{figure.caption.34}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:resnet_funnel}{{4.1}{23}{Our ResNet-50 architecture with a funnel layer for classification. Blue blocks represent the input from the ResNet-50 architecture, red blocks represent the final output layer, and green blocks represent our new funnel layers}{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Model Performance}{23}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Synthetic Variants}{23}{subsubsection*.39}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Overfitting on the CIFAR-100 dataset during training. The blue line represents the training accuracy, while the orange line represents the validation accuracy. The model overfits on the training data, resulting in a significant gap between the training and validation accuracy.}}{24}{figure.caption.37}\protected@file@percent }
\newlabel{fig:overfitting}{{4.2}{24}{Overfitting on the CIFAR-100 dataset during training. The blue line represents the training accuracy, while the orange line represents the validation accuracy. The model overfits on the training data, resulting in a significant gap between the training and validation accuracy}{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Model Accuracy}{25}{subsubsection*.42}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Taxonomy Generation}{25}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Relationship Selection Methods}{25}{subsection.4.2.1}\protected@file@percent }
\newlabel{sec:relationship_selection}{{4.2.1}{25}{Relationship Selection Methods}{subsection.4.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Synthetic Dataset Variants}{25}{subsubsection*.46}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Evaluation results on test sets. Models were checkpointed after every epoch and evaluated on the validation loss. The model with the lowest validation loss was selected for evaluation on the test set. Training time indicates the total duration from start to finish of model training.}}{26}{table.caption.44}\protected@file@percent }
\newlabel{tab:evaluation_results}{{4.1}{26}{Evaluation results on test sets. Models were checkpointed after every epoch and evaluated on the validation loss. The model with the lowest validation loss was selected for evaluation on the test set. Training time indicates the total duration from start to finish of model training}{table.caption.44}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Best EDR results for relationship discovery methods. For each dataset variant and method, the parameter values that yielded the lowest Edge Difference Ratio (EDR) are shown along with the corresponding F1-score.}}{27}{table.caption.50}\protected@file@percent }
\newlabel{tab:relationship_methods_best_edr}{{4.2}{27}{Best EDR results for relationship discovery methods. For each dataset variant and method, the parameter values that yielded the lowest Edge Difference Ratio (EDR) are shown along with the corresponding F1-score}{table.caption.50}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Critique on Synthetic Dataset Variants}{28}{subsubsection*.53}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Average performance metrics for relationship discovery methods with globally optimal parameters. Each method uses the parameter value that minimizes the average EDR across all dataset variants. Performance metrics are then averaged across all dataset variants using these optimal parameters.}}{29}{table.caption.51}\protected@file@percent }
\newlabel{tab:relationship_methods_global_optimal}{{4.3}{29}{Average performance metrics for relationship discovery methods with globally optimal parameters. Each method uses the parameter value that minimizes the average EDR across all dataset variants. Performance metrics are then averaged across all dataset variants using these optimal parameters}{table.caption.51}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Alternate Evaluation Methods - WordNet Synsets}{29}{subsubsection*.55}\protected@file@percent }
\newlabel{sec:wordnet_synsets}{{4.2.1}{29}{Alternate Evaluation Methods - WordNet Synsets}{subsubsection*.55}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Alternate Evaluation Methods - SVHN-MNIST}{30}{subsubsection*.58}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Alternate Evaluation Methods - Domain-Shift Synthetic Datasets}{31}{subsubsection*.61}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Evaluation results on test sets for domain-shifted experiments. Models were trained with different domain shift transformations and checkpointed after every epoch. The model with the lowest validation loss was selected for evaluation on the test set. Training time indicates the total duration from start to finish of model training.}}{31}{table.caption.63}\protected@file@percent }
\newlabel{tab:evaluation_results_domain_shifted}{{4.4}{31}{Evaluation results on test sets for domain-shifted experiments. Models were trained with different domain shift transformations and checkpointed after every epoch. The model with the lowest validation loss was selected for evaluation on the test set. Training time indicates the total duration from start to finish of model training}{table.caption.63}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Average performance metrics for relationship discovery methods with globally optimal parameters on domain-shifted experiments. Each method uses the parameter value that minimizes the average EDR across all domain-shifted dataset variants. Performance metrics are then averaged across all dataset variants using these optimal parameters.}}{32}{table.caption.64}\protected@file@percent }
\newlabel{tab:relationship_methods_global_optimal_domain_shifted}{{4.5}{32}{Average performance metrics for relationship discovery methods with globally optimal parameters on domain-shifted experiments. Each method uses the parameter value that minimizes the average EDR across all domain-shifted dataset variants. Performance metrics are then averaged across all dataset variants using these optimal parameters}{table.caption.64}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Universal Taxonomy Generation}{32}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Universal Models}{33}{section.4.3}\protected@file@percent }
\newlabel{sec:universal_models}{{4.3}{33}{Universal Models}{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Training}{33}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Modifications to Baseline Architecture}{33}{subsubsection*.69}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Multi-Domain Training Procedure}{34}{subsubsection*.71}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Performance}{34}{subsection.4.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Baseline ResNet model performance on individual datasets. These single-domain models serve as reference points for evaluating the universal models. Every baseline model was trained for 50 epochs.}}{35}{table.caption.72}\protected@file@percent }
\newlabel{tab:baseline_model_results}{{4.6}{35}{Baseline ResNet model performance on individual datasets. These single-domain models serve as reference points for evaluating the universal models. Every baseline model was trained for 50 epochs}{table.caption.72}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Universal model evaluation results for two-domain models trained on Caltech-101 + Caltech-256. Models were evaluated on the test sets of the individual domains. Domain accuracy values show performance differences compared to single-domain baseline models (see Table~\ref {tab:baseline_model_results}). Best results per column are shown in bold. All accuracy values are shown as percentages. Density Threshold models use parameter 0.6, Naive Threshold models use parameter 0.1.}}{35}{table.caption.73}\protected@file@percent }
\newlabel{tab:universal_model_results_2domain}{{4.7}{35}{Universal model evaluation results for two-domain models trained on Caltech-101 + Caltech-256. Models were evaluated on the test sets of the individual domains. Domain accuracy values show performance differences compared to single-domain baseline models (see Table~\ref {tab:baseline_model_results}). Best results per column are shown in bold. All accuracy values are shown as percentages. Density Threshold models use parameter 0.6, Naive Threshold models use parameter 0.1}{table.caption.73}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Universal model evaluation results for three-domain models trained on Caltech-101 + Caltech-256 + CIFAR-100. Models were evaluated on the test sets of the individual domains. Domain accuracy values show performance differences compared to single-domain baseline models (see Table~\ref {tab:baseline_model_results}). Best results per column are shown in bold. All accuracy values are shown as percentages. Density Threshold models use parameter 0.6, Naive Threshold models use parameter 0.1.}}{36}{table.caption.74}\protected@file@percent }
\newlabel{tab:universal_model_results_3domain}{{4.8}{36}{Universal model evaluation results for three-domain models trained on Caltech-101 + Caltech-256 + CIFAR-100. Models were evaluated on the test sets of the individual domains. Domain accuracy values show performance differences compared to single-domain baseline models (see Table~\ref {tab:baseline_model_results}). Best results per column are shown in bold. All accuracy values are shown as percentages. Density Threshold models use parameter 0.6, Naive Threshold models use parameter 0.1}{table.caption.74}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Feature Visualization}{37}{subsection.4.3.3}\protected@file@percent }
\newlabel{fig:caltech256_2domain}{{4.3a}{38}{Caltech-256 2-domain variant 1\\ ($\mu _{\text {concepts}}=180$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=3$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\newlabel{sub@fig:caltech256_2domain}{{a}{38}{Caltech-256 2-domain variant 1\\ ($\mu _{\text {concepts}}=180$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=3$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\newlabel{fig:caltech256_2domain_variant}{{4.3b}{38}{Caltech-256 2-domain variant 2\\ ($\mu _{\text {concepts}}=200$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=2$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\newlabel{sub@fig:caltech256_2domain_variant}{{b}{38}{Caltech-256 2-domain variant 2\\ ($\mu _{\text {concepts}}=200$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=2$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\newlabel{fig:caltech256_3domain}{{4.3c}{38}{Caltech-256 3-domain variant\\ ($\mu _{\text {concepts}}=180$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=5$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\newlabel{sub@fig:caltech256_3domain}{{c}{38}{Caltech-256 3-domain variant\\ ($\mu _{\text {concepts}}=180$, $\sigma ^2_{\text {concepts}}=10$,\\ $\mu _{\text {classes}}=5$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\newlabel{fig:cifar100_2domain}{{4.3d}{38}{CIFAR-100 2-domain variant\\ ($\mu _{\text {concepts}}=50$, $\sigma ^2_{\text {concepts}}=5$,\\ $\mu _{\text {classes}}=3$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\newlabel{sub@fig:cifar100_2domain}{{d}{38}{CIFAR-100 2-domain variant\\ ($\mu _{\text {concepts}}=50$, $\sigma ^2_{\text {concepts}}=5$,\\ $\mu _{\text {classes}}=3$, $\sigma ^2_{\text {classes}}=1$)}{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Synthetic dataset variants showing their relationship graphs before applying universal taxonomy algorithms. The number of concepts and classes per concept are sampled from truncated normal distributions with the parameters shown in each subfigure caption.}}{38}{figure.caption.40}\protected@file@percent }
\newlabel{fig:synthetic_variants}{{4.3}{38}{Synthetic dataset variants showing their relationship graphs before applying universal taxonomy algorithms. The number of concepts and classes per concept are sampled from truncated normal distributions with the parameters shown in each subfigure caption}{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Accuracy curves for all synthetic dataset variants. Each subplot shows training and validation accuracy over training steps for all domains in that variant. The models achieve final training accuracies of approximately 0.96-0.98 and validation accuracies of approximately 0.73-0.83.}}{39}{figure.caption.43}\protected@file@percent }
\newlabel{fig:all_training_runs}{{4.4}{39}{Accuracy curves for all synthetic dataset variants. Each subplot shows training and validation accuracy over training steps for all domains in that variant. The models achieve final training accuracies of approximately 0.96-0.98 and validation accuracies of approximately 0.73-0.83}{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Precision and recall plot of the \textbf  {naive thresholding method} for different thresholds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants.}}{40}{figure.caption.47}\protected@file@percent }
\newlabel{fig:naive_thresholding_precision_recall}{{4.5}{40}{Precision and recall plot of the \textbf {naive thresholding method} for different thresholds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants}{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Precision and recall plot of the \textbf  {density thresholding method} for different thresholds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants.}}{41}{figure.caption.48}\protected@file@percent }
\newlabel{fig:density_thresholding_precision_recall}{{4.6}{41}{Precision and recall plot of the \textbf {density thresholding method} for different thresholds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants}{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Precision and recall plot of the \textbf  {hypothesis method} for different upper bounds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants.}}{41}{figure.caption.49}\protected@file@percent }
\newlabel{fig:hypothesis_method_precision_recall}{{4.7}{41}{Precision and recall plot of the \textbf {hypothesis method} for different upper bounds on the Caltech-256 2-domain, Caltech-256 3-domain, and CIFAR-100 2-domain synthetic dataset variants}{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces An example of a bad WordNet cluster in a relationship graph between Caltech256 and Caltech101. These false positives occur commonly and make WordNet unsuitable as a ground truth taxonomy.}}{42}{figure.caption.56}\protected@file@percent }
\newlabel{fig:wordnet}{{4.8}{42}{An example of a bad WordNet cluster in a relationship graph between Caltech256 and Caltech101. These false positives occur commonly and make WordNet unsuitable as a ground truth taxonomy}{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces This figure shows the complete relationship graph between the SVHN and MNIST datasets. The relationships are unequivocal and straightforward, as the classes are identical across both datasets; however, they lack complexity.}}{42}{figure.caption.59}\protected@file@percent }
\newlabel{fig:svhn_mnist}{{4.9}{42}{This figure shows the complete relationship graph between the SVHN and MNIST datasets. The relationships are unequivocal and straightforward, as the classes are identical across both datasets; however, they lack complexity}{figure.caption.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Example images from the domain-shifted synthetic variants. We apply different transformations to the images of the original synthetic dataset to create two new domains. The first domain (Domain A) is a noisy greyscale variant, while the second domain (Domain B) is a rotated, blurry version of the original images, and the third domain (Domain C) has random erasings, shifted perspectives, and color jitter.}}{42}{figure.caption.62}\protected@file@percent }
\newlabel{fig:domain_shift}{{4.10}{42}{Example images from the domain-shifted synthetic variants. We apply different transformations to the images of the original synthetic dataset to create two new domains. The first domain (Domain A) is a noisy greyscale variant, while the second domain (Domain B) is a rotated, blurry version of the original images, and the third domain (Domain C) has random erasings, shifted perspectives, and color jitter}{figure.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces This figure shows the complete Caltech101-Caltech256 universal taxonomy. While most classes build smaller clusters build smaller clusters of 2-3 classes, some large clusters can be observed.}}{43}{figure.caption.65}\protected@file@percent }
\newlabel{fig:taxonomy}{{4.11}{43}{This figure shows the complete Caltech101-Caltech256 universal taxonomy. While most classes build smaller clusters build smaller clusters of 2-3 classes, some large clusters can be observed}{figure.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces In the Caltech101-Caltech256 universal taxonomy, this cluster only contains vehicles. The universal classes created can be interpreted as sharing a common concept of \enquote {wheel}.}}{43}{figure.caption.66}\protected@file@percent }
\newlabel{fig:wheel_concept}{{4.12}{43}{In the Caltech101-Caltech256 universal taxonomy, this cluster only contains vehicles. The universal classes created can be interpreted as sharing a common concept of \enquote {wheel}}{figure.caption.66}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces This example in the Caltech101-Caltech256 universal taxonomy shows a wrong relationship cluster towards the Caltech101 class \enquote {binocular}. Many of the Caltech256 classes do not have a suitable representation in the Caltech101 dataset and then connect to the Caltech101 class \enquote {binocular} instead.}}{43}{figure.caption.67}\protected@file@percent }
\newlabel{fig:bad_taxonomy}{{4.13}{43}{This example in the Caltech101-Caltech256 universal taxonomy shows a wrong relationship cluster towards the Caltech101 class \enquote {binocular}. Many of the Caltech256 classes do not have a suitable representation in the Caltech101 dataset and then connect to the Caltech101 class \enquote {binocular} instead}{figure.caption.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Training curves for universal models using both hypothesis and MCFP taxonomies on the multi-domain Caltech-101 + Caltech-256 dataset. Both models show stable convergence with the hypothesis taxonomy achieving slightly better performance.}}{44}{figure.caption.75}\protected@file@percent }
\newlabel{fig:universal_model_training_curves}{{4.14}{44}{Training curves for universal models using both hypothesis and MCFP taxonomies on the multi-domain Caltech-101 + Caltech-256 dataset. Both models show stable convergence with the hypothesis taxonomy achieving slightly better performance}{figure.caption.75}{}}
\@setckpt{sources/results}{
\setcounter{page}{45}
\setcounter{equation}{0}
\setcounter{enumi}{3}
\setcounter{enumii}{4}
\setcounter{enumiii}{3}
\setcounter{enumiv}{0}
\setcounter{footnote}{2}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{3}
\setcounter{subsection}{3}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{14}
\setcounter{table}{8}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{parentequation}{0}
\setcounter{su@anzahl}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{section@level}{2}
\setcounter{Item}{38}
\setcounter{Hfootnote}{4}
\setcounter{bookmark@seq@number}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{51}
\setcounter{maxnames}{99}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{2}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
}
